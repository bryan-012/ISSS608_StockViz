[
  {
    "objectID": "ISSS608_StockViz.html",
    "href": "ISSS608_StockViz.html",
    "title": "ISSS608_StockViz",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1 + 1\n\n[1] 2\n\n\nHi, testing testing"
  },
  {
    "objectID": "ISSS608_StockViz.html#quarto",
    "href": "ISSS608_StockViz.html#quarto",
    "title": "ISSS608_StockViz",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\n\n1 + 1\n\n[1] 2\n\n\nHi, testing testing"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISS608 Group Project StockViz",
    "section": "",
    "text": "Welcome to Project StockViz !"
  },
  {
    "objectID": "Proposal/Proposal.html",
    "href": "Proposal/Proposal.html",
    "title": "Project Proposal: StockViz",
    "section": "",
    "text": "Investors and traders often struggle with tracking their stock portfolio efficiently, especially when using multiple sources to monitor performance, technical indicators, and forecasts. Many existing platforms offer complex interfaces, overwhelming users with excessive data and advanced financial tools that are not always necessary for retail investors.\nThe goal of this project is to develop a simple and user-friendly stock portfolio tracking and analysis app using R Shiny. The app will allow users to:\n\nAdd and track stocks in their portfolio.\nView interactive visualizations of stock prices and performance.\nPerform basic technical analysis, such as Exponential Moving Averages (EMA).\nForecast future trends based on historical data.\nKeep the interface lightweight and intuitive, making it accessible to casual investors who wan a hassle-free experience."
  },
  {
    "objectID": "Proposal/Proposal.html#project-objectives",
    "href": "Proposal/Proposal.html#project-objectives",
    "title": "Proposal",
    "section": "",
    "text": "To create an app to keep track of personal stock portfolio.\nTo create an app that allows technical analysis and possibly forecasting."
  },
  {
    "objectID": "Proposal/Proposal.html#data",
    "href": "Proposal/Proposal.html#data",
    "title": "Proposal",
    "section": "",
    "text": "This project will utilize the tidyquant package to get access to the stock data whether real time or historical. It will connect us with financial and economic data from sources such as Yahoo! Finance, Alpha Vantage, FRED (Federal Reserve Economic Data), Bloomberg etc."
  },
  {
    "objectID": "Proposal/Proposal.html#r-packages",
    "href": "Proposal/Proposal.html#r-packages",
    "title": "Proposal",
    "section": "",
    "text": "Package\nUse\n\n\n\n\nshint\nweb application framework\n\n\ntidyverse\ncollection of R packages for data manipulation and visulization\n\n\ndplyr\npart of tidyverse, use for data manipulation and wrangling\n\n\nplotly\nfor interactive visualizations\n\n\nquantmod\nfor retrieving and modling financial stock market data\n\n\ntidyquant\nintegrating tidyverse principles into quantitative financial analysis\n\n\ndt\ninteractive, dynamic tables in Shint\n\n\nPerformanceAnalytics\nFor portfolio analysis\n\n\nTTR\nfor technical indicators"
  },
  {
    "objectID": "Proposal/Proposal.html#project-schedule",
    "href": "Proposal/Proposal.html#project-schedule",
    "title": "Proposal",
    "section": "",
    "text": "Project timeline\n1st Meeting: 05th March 2025 9-10pm\n1st Draft Proposal: 10th March 2025 9-10pm"
  },
  {
    "objectID": "Proposal/Proposal.html#project-overview-motivation",
    "href": "Proposal/Proposal.html#project-overview-motivation",
    "title": "Proposal",
    "section": "",
    "text": "Investors and traders often struggle with tracking their stock portfolio efficiently, especially when using multiple sources to monitor performance, technical indicators, and forecasts. Many existing platforms offer complex interfaces, overwhelming users with excessive data and advanced financial tools that are not always necessary for retail investors.\nThe goal of this project is to develop a simple and user-friendly stock portfolio tracking and analysis app using R Shiny. The app will allow users to:\n\nAdd and track stocks in their portfolio.\nView interactive visualizations of stock prices and performance.\nPerform basic technical analysis, such as Exponential Moving Averages (EMA).\nForecast future trends based on historical data.\nKeep the interface lightweight and intuitive, making it accessible to casual investors who wan a hassle-free experience."
  },
  {
    "objectID": "Proposal/Proposal.html#problem-statement",
    "href": "Proposal/Proposal.html#problem-statement",
    "title": "Proposal",
    "section": "",
    "text": "Tracking a stock portfolio efficiently is often challenging due to :\n\nOverly Complex Tools\n\n\nMany stock tracking platforms are designed for professional traders, making them too advanced for retail investors.\nMany free platforms lack integration of technical analysis tools like EMA in a simple manner.\n\n\nLack of Personalization\n\n\nIf users do not use such app, they often have to manually enter their stocks into spreadsheets to keep track of their portfolio especially if they use multiple trading platforms.\n\n\nNo Forecasting & Basic Technical Analysis\n\n\nMany free tools do not provide predictive insights, such as EMA-based signals or basic forecasting.\n\nHow Our App Solves These Problems\n✔User-friendly Interface: Simple and interactive dashboard for tracking portfolio performance.\n✔Technical Analysis Tools: Integration of EMA, SMA, and trend analysis.\n✔Forecasting Feature: Users can apply time-series forecasting models for price trends.\n✔Custom Portfolio Tracking: Users can add and remove stocks."
  },
  {
    "objectID": "Proposal/Proposal.html#prototype-sketches",
    "href": "Proposal/Proposal.html#prototype-sketches",
    "title": "Proposal",
    "section": "",
    "text": "Users are able to see an overview of their current portfolio. Some insights they are able to gain are their current portfolio value, profit and loss, and top 5 investments.\n\n\n\n\n\n\n\n\n\n\n\n\nUsers will use this to add or remove stocks in their portfolio. They will be able to view all the stocks in their portfolio on the right.\n\n\n\n\n\n\n\n\n\n\n\n\nUsers will be able to select the stocks they want to analyse, timeframe of the main line chart and indicators they would like to see on the main line chart. They will be able to see the main line chart of stock trends alongside stock data (open, close, high, low etc) and 2 time series visualizations of historical patterns.\n\n\n\n\n\n\n\n\n\n\n\n\nUsers will be able to select the stocks they want to analyse and the timeframe range and a heatmap showing the trading volume will be visible on the right."
  },
  {
    "objectID": "Proposal/Proposal.html#shiny-app-features",
    "href": "Proposal/Proposal.html#shiny-app-features",
    "title": "Proposal",
    "section": "",
    "text": "User can add/remove stocks to their portfolio\nTrack Profit and Loss\nExplore new stocks"
  },
  {
    "objectID": "Proposal/Proposal.html#methodology-approach",
    "href": "Proposal/Proposal.html#methodology-approach",
    "title": "Proposal",
    "section": "",
    "text": "Data Collection & Integration\n\nRetrieve stock price and trading volume data using tidyquant\nStandardize stock ticker formats and ensure consistency across multiple sources\n\nData Cleaning & Processing\n\nHandle any missing values, remove duplicates and format timestamps\nShape the data so it is ready to be used for time-series or comparative analysis when user inputs their stock\n\nFeature Engineering\n\nCompute our indicators such as MA, EMA, volatility measures, momentum indicators etc.\nCalculate portfolio returns, profit/loss, top 5 investments etc\n\n\n\n\n\n\nStock Portfolio\n\nUsers can input stock holdings, including ticker symbols, quantity, and purchase price\nDisplay real-time portfolio value, daily changes, profit/loss calculations\nInteractive time sliders to allow users to adjust the time range of analysis\nProvide visualizations of portfolio allocation using pie charts and performance graphs\n\nStock Analysis\n\nUsers can search and select stocks to view detailed performance insights\nDisplay historical stock price trends with line charts\nProvide indicators including EMA, SMA, RSI and Bollinger Bands for trend analysis\nHeatmap to show trading volume variations\nUsing time series analysis methods to visualize different historical patterns"
  },
  {
    "objectID": "Proposal/Proposal.html#data-preparation",
    "href": "Proposal/Proposal.html#data-preparation",
    "title": "Project Proposal: StockViz",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nData Collection & Integration\n\nRetrieve stock price and trading volume data using tidyquant\nStandardize stock ticker formats and ensure consistency across multiple sources\n\nData Cleaning & Processing\n\nHandle any missing values, remove duplicates and format timestamps\nShape the data so it is ready to be used for time-series or comparative analysis when user inputs their stock\n\nFeature Engineering\n\nCompute our indicators such as MA, EMA, volatility measures, momentum indicators etc.\nCalculate portfolio returns, profit/loss, top 5 investments etc"
  },
  {
    "objectID": "Proposal/Proposal.html#portfolio-management-and-stock-analysis",
    "href": "Proposal/Proposal.html#portfolio-management-and-stock-analysis",
    "title": "Project Proposal: StockViz",
    "section": "Portfolio Management and Stock Analysis",
    "text": "Portfolio Management and Stock Analysis\n\nStock Portfolio\n\nUsers can input stock holdings, including ticker symbols, quantity, and purchase price\nDisplay real-time portfolio value, daily changes, profit/loss calculations\nInteractive time sliders to allow users to adjust the time range of analysis\nProvide visualizations of portfolio allocation using pie charts and performance graphs\n\nStock Analysis\n\nUsers can search and select stocks to view detailed performance insights\nDisplay historical stock price trends with line charts\nProvide indicators including EMA, SMA, RSI and Bollinger Bands for trend analysis\nHeatmap to show trading volume variations\nUsing time series analysis methods to visualize different historical patterns"
  },
  {
    "objectID": "Proposal/Proposal.html#portfolio-dashboard",
    "href": "Proposal/Proposal.html#portfolio-dashboard",
    "title": "Project Proposal: StockViz",
    "section": "Portfolio Dashboard",
    "text": "Portfolio Dashboard\nUsers are able to see an overview of their current portfolio. Some insights they are able to gain are their current portfolio value, profit and loss, and top 5 investments."
  },
  {
    "objectID": "Proposal/Proposal.html#portfolio-manager",
    "href": "Proposal/Proposal.html#portfolio-manager",
    "title": "Project Proposal: StockViz",
    "section": "Portfolio Manager",
    "text": "Portfolio Manager\nUsers will use this to add or remove stocks in their portfolio. They will be able to view all the stocks in their portfolio on the right."
  },
  {
    "objectID": "Proposal/Proposal.html#stock-analysis",
    "href": "Proposal/Proposal.html#stock-analysis",
    "title": "Project Proposal: StockViz",
    "section": "Stock Analysis",
    "text": "Stock Analysis\nUsers will be able to select the stocks they want to analyse, timeframe of the main line chart and indicators they would like to see on the main line chart. They will be able to see the main line chart of stock trends alongside stock data (open, close, high, low etc) and 2 time series visualizations of historical patterns."
  },
  {
    "objectID": "Proposal/Proposal.html#trading-volume",
    "href": "Proposal/Proposal.html#trading-volume",
    "title": "Project Proposal: StockViz",
    "section": "Trading volume",
    "text": "Trading volume\nUsers will be able to select the stocks they want to analyse and the timeframe range and a heatmap showing the trading volume will be visible on the right."
  },
  {
    "objectID": "Prototype/forecasting.html",
    "href": "Prototype/forecasting.html",
    "title": "Time Series Forecasting",
    "section": "",
    "text": "Forecasting the stock market is a very complex task that involves analyzing the movements of past stock prices to predict future trends. Although there are many other external factors eg. political, economical, global events etc that could heavily impact the stock prices, our goal here is to only find the best prediction based on previous past trends.\nThis guide will provide an in-depth approach to stock market forecasting using R and the Modeltime framework, which integrates time series models with machine learning methods.\nThis guide aims to cover:\n\nExploratory Data Analysis (EDA) for understanding the time series data\nPreprocessing & Feature Engineering for model improvement\nModel Selection and Optimization, leveraging the many forecasting models we have\nComparative Model Evaluation to select the best predictive framework\nInteractive Data Visualization to analyze and interpret results."
  },
  {
    "objectID": "Prototype/forecasting.html#importing-libraries",
    "href": "Prototype/forecasting.html#importing-libraries",
    "title": "Time Series Forecasting",
    "section": "3.1 Importing Libraries",
    "text": "3.1 Importing Libraries\n\n\n\nLibrary\nUse case\n\n\n\n\ntidymodels\nML framework\n\n\ntimetk\nTime series feature engineering\n\n\nmodeltime\nForecasting framework\n\n\nquantmod\nFetch stock data\n\n\nlubridate\nDate-time manipulation\n\n\nplotly\nInteractive Visualization\n\n\nxgboost\nGradient boosting model\n\n\nrandomForest\nRandom Forest model\n\n\nkeras\nDeep Learning (LSTM)\n\n\ntidyverse\nData Manipulation and Visualization\n\n\n\n\nlibrary(tidyverse)      \nlibrary(tidymodels)      \nlibrary(timetk)       \nlibrary(modeltime)       \nlibrary(quantmod)      \nlibrary(lubridate)       \nlibrary(plotly)         \nlibrary(xgboost)        \nlibrary(randomForest)   \nlibrary(keras) \nlibrary(tidyquant)"
  },
  {
    "objectID": "Prototype/forecasting.html#fetching-and-preparing-stock-data",
    "href": "Prototype/forecasting.html#fetching-and-preparing-stock-data",
    "title": "Time Series Forecasting",
    "section": "3.2 Fetching and Preparing Stock Data",
    "text": "3.2 Fetching and Preparing Stock Data\nOur stock data will be retrieved from Yahoo Finance using quantmod. We focus on closing prices, which will serve as the primary target variable in our forecasting.\nLet us start by using the tq_get() function to see how the data is structured and what columns are available.\n\n\nShow the code\ntq_get(\"AAPL\")\n\n\n# A tibble: 2,570 × 8\n   symbol date        open  high   low close    volume adjusted\n   &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 AAPL   2015-01-02  27.8  27.9  26.8  27.3 212818400     24.3\n 2 AAPL   2015-01-05  27.1  27.2  26.4  26.6 257142000     23.6\n 3 AAPL   2015-01-06  26.6  26.9  26.2  26.6 263188400     23.6\n 4 AAPL   2015-01-07  26.8  27.0  26.7  26.9 160423600     24.0\n 5 AAPL   2015-01-08  27.3  28.0  27.2  28.0 237458000     24.9\n 6 AAPL   2015-01-09  28.2  28.3  27.6  28.0 214798000     24.9\n 7 AAPL   2015-01-12  28.1  28.2  27.2  27.3 198603200     24.3\n 8 AAPL   2015-01-13  27.9  28.2  27.2  27.6 268367600     24.5\n 9 AAPL   2015-01-14  27.3  27.6  27.1  27.5 195826400     24.4\n10 AAPL   2015-01-15  27.5  27.5  26.7  26.7 240056000     23.8\n# ℹ 2,560 more rows\n\n\nWe will take data from the last 2 years so that our model will learn from the most up-to-date patterns and trends.\n\nstock_symbol &lt;- \"AAPL\"\nstart_date &lt;- Sys.Date() - 730\nend_date &lt;- Sys.Date()\n\nstock_data &lt;- tq_get(stock_symbol, from= start_date, to= end_date)\n\nstock_tbl &lt;- stock_data %&gt;%\n  select(date, close) %&gt;%\n  rename(Date= date, Value= close)"
  },
  {
    "objectID": "Prototype/forecasting.html#summary-statistics",
    "href": "Prototype/forecasting.html#summary-statistics",
    "title": "Time Series Forecasting",
    "section": "4.1 Summary Statistics",
    "text": "4.1 Summary Statistics\n\n\nShow the code\nsummary(stock_tbl)\n\n\n      Date                Value      \n Min.   :2023-03-23   Min.   :157.6  \n 1st Qu.:2023-09-21   1st Qu.:177.4  \n Median :2024-03-21   Median :191.0  \n Mean   :2024-03-21   Mean   :199.4  \n 3rd Qu.:2024-09-19   3rd Qu.:225.0  \n Max.   :2025-03-21   Max.   :259.0  \n\n\n\n\n\n\n\n\nInsights\n\n\n\nThere seems to have a big range between the min and max, we should take this volatility into account when doing our forecasting"
  },
  {
    "objectID": "Prototype/forecasting.html#distribution",
    "href": "Prototype/forecasting.html#distribution",
    "title": "Time Series Forecasting",
    "section": "4.2 Distribution",
    "text": "4.2 Distribution\n\n\nShow the code\nstock_tbl %&gt;%\n  ggplot(aes(x = Value)) +\n  geom_histogram(fill = \"blue\", bins = 30, alpha = 0.7) +\n  theme_minimal() +\n  ggtitle(\"Stock Price Distribution\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThe distribution is not normally distributed, using non-linear models would be better in our forecasting, such as LSTM, XGBoost or Prophet."
  },
  {
    "objectID": "Prototype/forecasting.html#outliers",
    "href": "Prototype/forecasting.html#outliers",
    "title": "Time Series Forecasting",
    "section": "4.3 Outliers",
    "text": "4.3 Outliers\n\n\nShow the code\nstock_tbl %&gt;%\n  ggplot(aes(y = Value)) +\n  geom_boxplot(fill = \"red\", alpha = 0.5) +\n  theme_minimal() +\n  ggtitle(\"Stock Price Outliers\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThere are no extreme outliers which is good but as mentioned above the IQR is large which suggests stock price fluctuations"
  },
  {
    "objectID": "Prototype/forecasting.html#time-series-decomposition",
    "href": "Prototype/forecasting.html#time-series-decomposition",
    "title": "Time Series Forecasting",
    "section": "4.4 Time Series Decomposition",
    "text": "4.4 Time Series Decomposition\n\n\nShow the code\nstock_tbl %&gt;%\n  plot_stl_diagnostics(Date,Value)\n\n\n\n\n\n\nShow the code\nstock_tbl %&gt;%\n  mutate(Rolling_Avg = rollmean(Value, k=30, fill =NA)) %&gt;%\n  ggplot(aes(x=Date)) +\n  geom_line(aes(y=Value),color=\"blue\")+\n  geom_line(aes(y=Rolling_Avg), color=\"red\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nThere is a clear upward trend with fluctuations, meaning a trend following model would work well like ARIMA, XGBoost. There is also seasonality detected as we see some periodic effects so we can also consider SARIMA, Prophet."
  },
  {
    "objectID": "Prototype/forecasting.html#arima-model",
    "href": "Prototype/forecasting.html#arima-model",
    "title": "Time Series Forecasting",
    "section": "6.1 ARIMA Model",
    "text": "6.1 ARIMA Model\nWe initialize an ARIMA model using arima_reg() and then train it using the training data where Value is the target variable and Date is the independent variable.\nThis model analyzes historical stock prices to identify trends and patterns, assuming that future prices are linearly dependent on past observations.\n\nmodel_arima &lt;- arima_reg() %&gt;%\n  set_engine(\"auto_arima\") %&gt;%\n  fit(Value ~ Date, data = training(splits))\n\n\n\n\n\n\n\nNote\n\n\n\nThe result mentions frequency = 5 observations per 1 week, indicating 5 trading days per week"
  },
  {
    "objectID": "Prototype/forecasting.html#prophet-model",
    "href": "Prototype/forecasting.html#prophet-model",
    "title": "Time Series Forecasting",
    "section": "6.2 Prophet Model",
    "text": "6.2 Prophet Model\nFor the Prophet Model, we require some data preprocessing, we need to extract time based features from the Date column, normalize numeric date-based features, apply fourier transformation to capture seasonality and convert categorical into dummy variables. This is because Prophet handles seasonality and trend shifts in time series data.\nWe use prophet_reg() to initialize the model, workflow() to combine our preprocessed recipe and train it with our training split.\n\nrecipe_spec &lt;- recipe(Value ~ Date, training(splits)) %&gt;%\n  step_timeseries_signature(Date) %&gt;%\n  step_rm(contains(\"am.pm\"), contains(\"hour\"), contains(\"minute\"),\n          contains(\"second\"), contains(\"xts\"), contains(\"half\"),\n          contains(\".iso\")) %&gt;%\n  step_normalize(Date_index.num) %&gt;%\n  step_fourier(Date, period = 12, K = 1) %&gt;%\n  step_dummy(all_nominal())\n\nworkflow_fit_prophet &lt;- workflow() %&gt;%\n  add_model(\n    prophet_reg() %&gt;% set_engine(\"prophet\")\n  ) %&gt;%\n  add_recipe(recipe_spec) %&gt;%\n  fit(training(splits))"
  },
  {
    "objectID": "Prototype/forecasting.html#xgboost",
    "href": "Prototype/forecasting.html#xgboost",
    "title": "Time Series Forecasting",
    "section": "6.3 XGBoost",
    "text": "6.3 XGBoost\nFor the XGBoost model, we do some data preprocessing as well, we extract useful features from the Date column such as year, month, day of year and week, we convert categorical into dummy variables and normalize numeric predictors.\nWe define the gradient boosting tree for regression tasks and use workflow() to combine our model and recipe.\n\nrecipe_spec_parsnip &lt;- recipe(Value ~ Date, data = training(splits)) %&gt;%\n  step_date(Date, features = c(\"year\", \"month\", \"doy\", \"week\")) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;%  \n  step_normalize(all_numeric_predictors()) %&gt;%  \n  step_rm(Date) \nprepped_recipe &lt;- prep(recipe_spec_parsnip)\n\ntrain_processed &lt;- juice(prepped_recipe)\n\nX_train &lt;- train_processed %&gt;% select(-Value)\ny_train &lt;- train_processed$Value\n\nsapply(X_train, class)\n\n     Date_year       Date_doy      Date_week Date_month_Feb Date_month_Mar \n     \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\" \nDate_month_Apr Date_month_May Date_month_Jun Date_month_Jul Date_month_Aug \n     \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\" \nDate_month_Sep Date_month_Oct Date_month_Nov Date_month_Dec \n     \"numeric\"      \"numeric\"      \"numeric\"      \"numeric\" \n\nworkflow_fit_xgboost &lt;- workflow() %&gt;%\n  add_model(boost_tree(mode = \"regression\") %&gt;% set_engine(\"xgboost\")) %&gt;%\n  add_recipe(recipe_spec_parsnip) %&gt;%\n  fit(training(splits))"
  },
  {
    "objectID": "Prototype/forecasting.html#ets",
    "href": "Prototype/forecasting.html#ets",
    "title": "Time Series Forecasting",
    "section": "6.4 ETS",
    "text": "6.4 ETS\nThe ETS model determines whether the time series has error, trend and seasonality, we define this by using exp_smoothing().\n\nmodel_ets &lt;- exp_smoothing() %&gt;%\n  set_engine(\"ets\") %&gt;%\n  fit(Value ~ Date, data = training(splits))"
  },
  {
    "objectID": "Prototype/forecasting.html#random-forest",
    "href": "Prototype/forecasting.html#random-forest",
    "title": "Time Series Forecasting",
    "section": "6.5 Random Forest",
    "text": "6.5 Random Forest\nFor random forest, we do some preprocessing, we extract features from date, convert categorical variables to dummy and normalize numerical features.\nWe define the model by using rand_forest(), with 500 trees and 50 minimum samples required to make a split in the tree.\n\nrecipe_rf &lt;- recipe(Value ~ Date, data = training(splits)) %&gt;%\n  step_date(Date, features = c(\"year\", \"month\", \"dow\")) %&gt;% \n  step_dummy(all_nominal_predictors()) %&gt;%  \n  step_normalize(all_numeric_predictors()) \n\nmodel_rf &lt;- rand_forest(\n  mode = \"regression\", \n  trees = 500,          \n  min_n = 50            \n) %&gt;%\n  set_engine(\"ranger\")\n\nworkflow_fit_rf &lt;- workflow() %&gt;%\n  add_model(model_rf) %&gt;%\n  add_recipe(recipe_rf) %&gt;%\n  fit(training(splits))"
  },
  {
    "objectID": "Prototype/forecasting.html#plotting-our-forecast-models",
    "href": "Prototype/forecasting.html#plotting-our-forecast-models",
    "title": "Time Series Forecasting",
    "section": "Plotting our forecast models",
    "text": "Plotting our forecast models\n\n\nShow the code\ncalibrated_tbl &lt;- calibrated_tbl %&gt;%\n  mutate(.model_desc = case_when(\n    .model_id ==1 ~ \"ARIMA\",\n    str_detect(.model_desc, \"RANGER\") ~ \"Random Forest\",\n    TRUE ~ .model_desc\n  ))\nforecast_tbl &lt;- calibrated_tbl %&gt;%\n  modeltime_forecast(new_data = testing(splits), actual_data = stock_tbl)\n\nplot_modeltime_forecast(forecast_tbl, .interactive = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nInsight\n\n\n\nFrom the visualization we can identify XGBoost and Prophet provide more realistic and adaptive trends.\nARIMA & ETS are more static and this may be due to not being able to handle rapid changes well.\nRandom Forest shows instability as the model may not have been calibrated well."
  },
  {
    "objectID": "Prototype/forecasting.html#model-evaluation",
    "href": "Prototype/forecasting.html#model-evaluation",
    "title": "Time Series Forecasting",
    "section": "Model Evaluation",
    "text": "Model Evaluation\n\n\nShow the code\ncalibrated_tbl %&gt;%\n  modeltime_accuracy() %&gt;%\n  table_modeltime_accuracy(.round_digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nAccording to the numbers it seems that ETS and Prophet are best models in this case with the lowest error.\n\n\n\n\nShow the code\nmodel_residuals &lt;- calibrated_tbl %&gt;%\nmodeltime_residuals()\nmodel_residuals %&gt;%\n  plot_modeltime_residuals(.type = \"timeplot\")\n\n\n\n\n\n\n\n\nShow the code\nmodel_residuals %&gt;%\n  plot_modeltime_residuals(.type = \"acf\")\n\n\n\n\n\n\n\n\nShow the code\nmodel_residuals %&gt;%\n  plot_modeltime_residuals(.type = \"seasonality\")\n\n\n\n\n\n\n\n\n\n\n\n\nThinking\n\n\n\nIt might not be a good idea to just include XGBoost or Random Forest but giving a variety of forecasting models options into our application may allow for better decision making."
  },
  {
    "objectID": "Prototype/forecasting.html#visualizing-comparison",
    "href": "Prototype/forecasting.html#visualizing-comparison",
    "title": "Time Series Forecasting",
    "section": "Visualizing Comparison",
    "text": "Visualizing Comparison\n\n\nShow the code\naccuracy_tbl &lt;- calibrated_tbl %&gt;%\n  modeltime_accuracy() %&gt;%\n  pivot_longer(cols = c(mae, rmse, mape),\n               names_to = \"Metric\", values_to = \"Value\") %&gt;%\n  mutate(.model_desc = case_when(\n    .model_desc == \"PROPHET W/ REGRESSORS\" ~ \"Prophet\",\n    .model_desc == \"1_UPDATE: ARIMA(0,1,0)(0,1,1)[5] WITH DRIFT\" ~ \"ARIMA\",\n    .model_desc == \"4_ETS(M,N,N)\" ~ \"ETS\",\n    TRUE ~ .model_desc  \n  ))\n\nggplot(accuracy_tbl, aes(x = reorder(.model_desc, Value), y = Value, fill = Metric)) +\n  geom_col(position = \"dodge\", width = 0.6) +  \n  facet_wrap(~ Metric, scales = \"free_y\") +  \n  coord_flip() +  # Flip for readability\n  scale_fill_manual(values = c(\"mae\" = \"#E74C3C\", \"mape\" = \"#2ECC71\", \"rmse\" = \"#3498DB\")) + \n  labs(title = \"Model Performance Comparison\",\n       x = \"Model\",\n       y = \"Metric Value\") +\n  theme_minimal(base_size = 14) +  \n  theme(axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1),\n        legend.position = \"bottom\")"
  },
  {
    "objectID": "Prototype/forecasting.html#projecting-forward",
    "href": "Prototype/forecasting.html#projecting-forward",
    "title": "Time Series Forecasting",
    "section": "Projecting Forward",
    "text": "Projecting Forward\nWe now plot a 2 month projection forward using our models. This will be the forecast used in our shiny app, where users can calibrate how many months ahead they want to visualize, of course with a cap.\n\n\nShow the code\ncalibrated_tbl %&gt;%\n  modeltime_refit(stock_tbl) %&gt;%\n  modeltime_forecast(h = \"2 months\", actual_data = stock_tbl) %&gt;%\n\n  plot_modeltime_forecast(.interactive = TRUE)"
  },
  {
    "objectID": "Prototype/confirmatory_analysis.html",
    "href": "Prototype/confirmatory_analysis.html",
    "title": "Confirmatory Analysis",
    "section": "",
    "text": "We will load the following packages by using the pacman::p_load function:\ntidyquant, tidyverse, xts, timeDate, lubridate, writexl, broom, sandwich, lmtest, dplyr, tidyr, GGally, corrplot, zoo, plotly, scales, moments, gt, gtExtras\n\n\n\nOur stock data will be retrieved from Yahoo Finance using quantmod. In Shiny App, Data will be pulled real-time according to user’s selection. For now below data will be used to demonstrate EDA and CDA.\n\n\n\n\n# Simulate user portfolio (can be dynamic in Shiny later) \nuser_portfolio &lt;- data.frame(\n  symbol = c(\"AAPL\", \"MSFT\", \"TSLA\", \"NVDA\", \"AMZN\", \"NVDA\"),\n  buy_date = as.Date(c(\"2022-01-15\", \"2022-02-20\", \"2022-03-10\", \"2022-04-05\", \"2022-05-12\", \"2024-01-17\")),\n  quantity = c(10, 15, 5, 8, 12, 7)\n)\nuser_portfolio\n\n  symbol   buy_date quantity\n1   AAPL 2022-01-15       10\n2   MSFT 2022-02-20       15\n3   TSLA 2022-03-10        5\n4   NVDA 2022-04-05        8\n5   AMZN 2022-05-12       12\n6   NVDA 2024-01-17        7\n\n\n\n\n\n\n\n\nIn R Shiny, user will be able to select the stocks they have in their Portfolio. From the selected stocks, EDA will run accordingly.\n\n\n\nIn R Shiny, user will be able to select the stocks they have in their Portfolio. From the selected stocks, EDA will run accordingly.\n\n\n\n# 📦 Function: Prepare User Portfolio Input\ntidy_user_portfolio &lt;- function() {\n  data.frame(\n    symbol = c(\"AAPL\", \"MSFT\", \"TSLA\", \"NVDA\", \"AMZN\", \"NVDA\"),\n    buy_date = as.Date(c(\"2022-01-15\", \"2022-02-20\", \"2022-03-10\", \"2022-04-05\", \"2022-05-12\", \"2024-01-17\")),\n    quantity = c(10, 15, 5, 8, 12, 7),\n    buy_price = c(NA, 287, NA, 26, NA, 55)\n  )\n}\n\n\n\n\n\n\n# 📈 Pull Stock Data\nget_stock_data &lt;- function(user_portfolio) {\n  data_start &lt;- min(user_portfolio$buy_date, na.rm = TRUE)\n  stock_data_raw &lt;- tq_get(unique(user_portfolio$symbol), from = data_start, to = Sys.Date())\n\n  stock_data &lt;- stock_data_raw %&gt;%\n    group_by(symbol, date) %&gt;%\n    summarise(\n      open = first(open),\n      high = max(high, na.rm = TRUE),\n      low = min(low, na.rm = TRUE),\n      close = last(close),\n      volume = sum(volume, na.rm = TRUE),\n      adjusted = last(adjusted),\n      .groups = \"drop\"\n    )\n\n  return(stock_data)\n}\n\n\n# Initialize storage lists\ntrack_portfolio_returns &lt;- function(user_portfolio, stock_data) {\n  portfolio_results &lt;- list()\n  summary_list &lt;- list()\n  skipped_stocks &lt;- c()\n\n  for (i in 1:nrow(user_portfolio)) {\n    stock &lt;- user_portfolio$symbol[i]\n    buy_date_input &lt;- user_portfolio$buy_date[i]\n    qty &lt;- user_portfolio$quantity[i]\n    buy_price_user &lt;- user_portfolio$buy_price[i]\n\n    stock_prices &lt;- stock_data %&gt;% filter(symbol == stock)\n    available_dates &lt;- stock_prices$date\n    valid_buy_date &lt;- max(available_dates[available_dates &lt;= buy_date_input])\n\n    if (is.infinite(valid_buy_date) | is.na(valid_buy_date)) {\n      warning(paste(\"No available trading date before\", buy_date_input, \"for\", stock, \"- skipping...\"))\n      skipped_stocks &lt;- c(skipped_stocks, stock)\n      next\n    }\n\n    day_row &lt;- stock_prices %&gt;% filter(date == valid_buy_date)\n    day_high &lt;- max(day_row$high, na.rm = TRUE)\n    day_low  &lt;- min(day_row$low, na.rm = TRUE)\n    median_price &lt;- median(day_row$adjusted, na.rm = TRUE)\n\n    if (is.na(median_price) || median_price == 0) {\n      warning(paste(\"⚠ No valid price data on\", valid_buy_date, \"for\", stock, \"- skipping...\"))\n      next\n    }\n\n    if (!is.na(buy_price_user)) {\n      buy_price &lt;- buy_price_user\n      buy_price_source &lt;- \"User Input\"\n      price_out_of_range &lt;- buy_price &lt; day_low | buy_price &gt; day_high\n      if (price_out_of_range) {\n        warning(paste0(\"⚠ BUY PRICE OUT OF RANGE for \", stock, \": $\", round(buy_price_user, 2),\n                       \" is outside [$\", round(day_low, 2), \" – $\", round(day_high, 2), \"] on \", valid_buy_date))\n      }\n    } else {\n      buy_price &lt;- median_price\n      buy_price_source &lt;- \"Median Price\"\n      price_out_of_range &lt;- FALSE\n    }\n\n    tracking_data &lt;- stock_prices %&gt;%\n      filter(date &gt;= valid_buy_date) %&gt;%\n      arrange(date) %&gt;%\n      mutate(\n        return_since_buy = (adjusted / buy_price) - 1,\n        current_value = adjusted * qty,\n        stock = stock,\n        buy_date = valid_buy_date,\n        quantity = qty,\n        buy_price = buy_price,\n        invested_amount = buy_price * qty,\n        holding_value = adjusted * qty,\n        unrealized_return = (adjusted - buy_price) * qty,\n        position_id = paste0(stock, \"_\", valid_buy_date)\n      )\n\n    portfolio_results[[i]] &lt;- tracking_data\n\n    summary_list[[i]] &lt;- tibble(\n      stock = stock,\n      buy_date = valid_buy_date,\n      quantity = qty,\n      buy_price = buy_price,\n      buy_price_source = buy_price_source,\n      day_low = day_low,\n      day_high = day_high,\n      price_out_of_range = price_out_of_range,\n      invested_amount = buy_price * qty,\n      current_price = tail(tracking_data$adjusted, 1),\n      current_value = tail(tracking_data$holding_value, 1),\n      unrealized_return = tail(tracking_data$unrealized_return, 1),\n      return_percent = tail(tracking_data$return_since_buy, 1)\n    )\n  }\n\n  list(\n    portfolio_tracking_all = bind_rows(portfolio_results),\n    portfolio_summary = bind_rows(summary_list),\n    skipped_stocks = skipped_stocks\n  )\n}\n\n\n\n\n# Clean summary\ngenerate_portfolio_summary &lt;- function(portfolio_summary) {\n  portfolio_summary_clean &lt;- portfolio_summary %&gt;%\n    mutate(\n      `Buy Price Status` = case_when(\n        is.na(price_out_of_range) ~ \"N/A\",\n        price_out_of_range ~ \"❌ Out of Range\",\n        TRUE ~ \"✔ OK\"\n      ),\n      `Return (%)` = percent(return_percent),\n      `Unrealized Return ($)` = dollar(unrealized_return)\n    ) %&gt;%\n    select(\n      Stock = stock,\n      `Buy Date` = buy_date,\n      Quantity = quantity,\n      `Buy Price ($)` = buy_price,\n      `Price Source` = buy_price_source,\n      `Day Low ($)` = day_low,\n      `Day High ($)` = day_high,\n      `Buy Price Status`,\n      `Invested Amount ($)` = invested_amount,\n      `Current Price ($)` = current_price,\n      `Current Value ($)` = current_value,\n      `Unrealized Return ($)`,\n      `Return (%)`\n    )\n\n  # 📊 Return GT Table\n  portfolio_summary_clean %&gt;%\n    gt() %&gt;%\n    tab_header(title = \"📊 Portfolio Summary with % and $ Return\") %&gt;%\n    fmt_currency(columns = c(\n      `Buy Price ($)`, `Day Low ($)`, `Day High ($)`,\n      `Invested Amount ($)`, `Current Price ($)`, `Current Value ($)`\n    )) %&gt;%\n    data_color(\n      columns = `Buy Price Status`,\n      fn = function(x) ifelse(x == \"❌ Out of Range\", \"tomato\", \"lightgreen\")\n    )\n}\n\n\n\n\n\n\n# Step 1: Simulate or get user portfolio\nuser_portfolio &lt;- tidy_user_portfolio()\n\n# Step 2: Pull stock data\nstock_data &lt;- get_stock_data(user_portfolio)\n\n# Step 3: Track portfolio returns\nportfolio_output &lt;- track_portfolio_returns(user_portfolio, stock_data)\n\nWarning in max.default(structure(numeric(0), class = \"Date\"), na.rm = FALSE):\nno non-missing arguments to max; returning -Inf\n\n\nWarning in track_portfolio_returns(user_portfolio, stock_data): No available\ntrading date before 2022-01-15 for AAPL - skipping...\n\n# Extract outputs from the list\nportfolio_tracking_all &lt;- portfolio_output$portfolio_tracking_all\nportfolio_summary &lt;- portfolio_output$portfolio_summary\nskipped_stocks &lt;- portfolio_output$skipped_stocks\n\n\n\n\n\nif (length(skipped_stocks) &gt; 0) {\n  message(\"⚠ Skipped Stocks: \", paste(skipped_stocks, collapse = \", \"))\n}\n\n⚠ Skipped Stocks: AAPL\n\n\n\n\n\n\n# Step 4: Show portfolio summary table (rendered using gt)\ngenerate_portfolio_summary(portfolio_summary)\n\n\n\n\n\n\n\n📊 Portfolio Summary with % and $ Return\n\n\nStock\nBuy Date\nQuantity\nBuy Price ($)\nPrice Source\nDay Low ($)\nDay High ($)\nBuy Price Status\nInvested Amount ($)\nCurrent Price ($)\nCurrent Value ($)\nUnrealized Return ($)\nReturn (%)\n\n\n\n\nMSFT\n2022-02-18\n15\n$287.00\nUser Input\n$286.31\n$293.86\n✔ OK\n$4,305.00\n$391.26\n$5,868.90\n$1,563.90\n36%\n\n\nTSLA\n2022-03-10\n5\n$279.43\nMedian Price\n$270.12\n$284.82\n✔ OK\n$1,397.17\n$248.71\n$1,243.55\n-$153.62\n-11%\n\n\nNVDA\n2022-04-05\n8\n$26.00\nUser Input\n$25.82\n$27.32\n✔ OK\n$208.00\n$117.70\n$941.60\n$733.60\n353%\n\n\nAMZN\n2022-05-12\n12\n$106.93\nMedian Price\n$102.41\n$110.78\n✔ OK\n$1,283.17\n$196.21\n$2,354.52\n$1,071.35\n83%\n\n\nNVDA\n2024-01-17\n7\n$55.00\nUser Input\n$54.74\n$56.47\n✔ OK\n$385.00\n$117.70\n$823.90\n$438.90\n114%\n\n\n\n\n\n\n\n\n\n\n\nggplot(portfolio_tracking_all, aes(x = date, y = return_since_buy, color = position_id)) +\n  geom_line(size = 1) +\n  labs(title = \"Cumulative Return Since Buy Date (By Position)\", y = \"Return\", x = \"Date\") +\n  scale_y_continuous(labels = scales::percent)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(\n  data = portfolio_tracking_all,\n  x = ~date,\n  y = ~holding_value,\n  color = ~position_id,\n  type = 'scatter',\n  mode = 'lines',\n  text = ~paste0(\n    \"Stock: \", stock, \"&lt;br&gt;\",\n    \"Buy Date: \", buy_date, \"&lt;br&gt;\",\n    \"Date: \", format(date, \"%Y-%m-%d\"), \"&lt;br&gt;\",\n    \"Value: $\", format(round(holding_value, 2), big.mark = \",\")\n  ),\n  hoverinfo = \"text\"\n) %&gt;%\n  layout(\n    title = \"Individual Stock Value Over Time (By Buy-in Position)\",\n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"Holding Value (USD)\")\n  )\n\n\n\n\n\n\n\n\n\ntotal_portfolio &lt;- portfolio_tracking_all %&gt;%\n  group_by(date) %&gt;%\n  summarise(total_value = sum(holding_value), .groups = \"drop\")\n\nggplot(total_portfolio, aes(x = date, y = total_value)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +\n  labs(title = \"Total Portfolio Value Over Time\", y = \"Value (USD)\", x = \"Date\") +\n  scale_y_continuous(labels = scales::dollar)\n\n\n\n\n\n\n\n\n\n\n\n\nSimulated multi-stock portfolio\nLive Yahoo Finance data via tq_get()\nReturn tracking since individual buy dates\nPortfolio-level return and value plots\n\n\ncolnames(portfolio_tracking_all)\n\n [1] \"symbol\"            \"date\"              \"open\"             \n [4] \"high\"              \"low\"               \"close\"            \n [7] \"volume\"            \"adjusted\"          \"return_since_buy\" \n[10] \"current_value\"     \"stock\"             \"buy_date\"         \n[13] \"quantity\"          \"buy_price\"         \"invested_amount\"  \n[16] \"holding_value\"     \"unrealized_return\" \"position_id\"      \n\n\n\n\n\nggplot(stock_data, aes(x = date, y = adjusted, color = symbol)) +\n  geom_line() +\n  labs(title = \"Adjusted Closing Price Over Time\", y = \"Adjusted Price\", x = \"Date\")\n\n\n\n\n\n\n\n\n\n\n\n\nstock_data &lt;- stock_data %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    daily_return = adjusted / lag(adjusted) - 1,\n    rolling_vol_20 = rollapply(daily_return, width = 20, FUN = sd, fill = NA, align = \"right\")\n  ) %&gt;%\n  ungroup()\n\nggplot(stock_data %&gt;% filter(!is.na(rolling_vol_20)), \n       aes(x = date, y = rolling_vol_20, color = symbol)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"20-Day Rolling Volatility (Standard Deviation of Daily Returns)\",\n    x = \"Date\",\n    y = \"Rolling Volatility (Std Dev)\"\n  ) +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\nObservations:\n\nTSLA (Purple Line) shows the highest volatility overall. It fluctuates often and peaks above 6%, meaning high price swings daily.\nMSFT (Green Line) is the least volatile, maintaining a very consistent low volatility around 1–2%, reflecting its status as a stable, mature stock.\nNVDA (Cyan) and AMZN (Red) fluctuate in between — but note that NVDA has occasional sharp volatility spikes, likely due to earnings or news events.\nSpikes in volatility (upward jumps) are usually tied to market news, economic events, earnings releases, or crashes/rallies.\nPeriods of low volatility indicate price stability or consolidation phases.\n\n\n\n\n\n\n\n\nportfolio_tracking_all %&gt;%\n  group_by(position_id) %&gt;%\n  summarise(\n    stock = first(stock),\n    buy_date = first(buy_date),\n    mean_return = mean(return_since_buy, na.rm = TRUE),\n    sd_return = sd(return_since_buy, na.rm = TRUE),\n    median_return = median(return_since_buy, na.rm = TRUE),\n    min_return = min(return_since_buy, na.rm = TRUE),\n    max_return = max(return_since_buy, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# A tibble: 5 × 8\n  position_id    stock buy_date   mean_return sd_return median_return min_return\n  &lt;chr&gt;          &lt;chr&gt; &lt;date&gt;           &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 AMZN_2022-05-… AMZN  2022-05-12       0.393     0.384         0.313    -0.235 \n2 MSFT_2022-02-… MSFT  2022-02-18       0.175     0.254         0.147    -0.269 \n3 NVDA_2022-04-… NVDA  2022-04-05       1.40      1.75          0.750    -0.569 \n4 NVDA_2024-01-… NVDA  2024-01-17       1.06      0.437         1.16      0.0188\n5 TSLA_2022-03-… TSLA  2022-03-10      -0.141     0.237        -0.164    -0.613 \n# ℹ 1 more variable: max_return &lt;dbl&gt;\n\n\nmean_return: Daily gain on average\nsd_return: Daily volatility\nmedian_return: Median\nmin_return: Minimum return\nmax_return: Maximum return\n\n\n\n\nportfolio_tracking_all &lt;- portfolio_tracking_all %&gt;%\n  arrange(stock, buy_date, date) %&gt;%\n  group_by(position_id) %&gt;%\n  mutate(\n    cumulative_return = cumprod(1 + coalesce(return_since_buy, 0))\n  ) %&gt;%\n  ungroup()\n\nggplot(portfolio_tracking_all, aes(x = date, y = return_since_buy, color = position_id)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Cumulative Return Since Buy Date (Per Buy-in)\",\n    x = \"Date\",\n    y = \"Cumulative Return\"\n  ) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ensure daily return is available (if not already calculated)\nstock_data &lt;- stock_data %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(daily_return = adjusted / lag(adjusted) - 1) %&gt;%\n  ungroup()\n\n# Summarise to ensure one return per symbol-date (safety step)\nreturns_clean &lt;- stock_data %&gt;%\n  group_by(date, symbol) %&gt;%\n  summarise(daily_return = mean(daily_return, na.rm = TRUE), .groups = \"drop\")\n\n# Pivot wider\nreturns_matrix &lt;- returns_clean %&gt;%\n  pivot_wider(names_from = symbol, values_from = daily_return)\n\n# Ensure numeric\nreturns_matrix &lt;- returns_matrix %&gt;%\n  mutate(across(-date, as.numeric))\n\n# Compute correlation matrix\nreturns_corr &lt;- cor(returns_matrix %&gt;% select(-date), use = \"pairwise.complete.obs\")\n\n# Plot\ncorrplot(\n  returns_corr,\n  method = \"color\",\n  addCoef.col = \"black\",\n  number.cex = 0.8,\n  title = \"Daily Return Correlation Matrix\",\n  mar = c(0, 0, 2, 0)\n)\n\n\n\n\n\n\n\n\nObservation:\n\nAMZN and MSFT show the highest correlation in your portfolio — likely due to their similar sector dynamics (large-cap tech, index-driven movements).\n\n\n\n\n# Step 1: Calculate mean return and volatility per stock\nreturn_volatility_stats &lt;- stock_data %&gt;%\n  group_by(symbol) %&gt;%\n  summarise(\n    mean_return = mean(daily_return, na.rm = TRUE),\n    volatility = sd(daily_return, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Step 2: Plot the Risk–Return scatter plot\nggplot(return_volatility_stats, aes(x = volatility, y = mean_return, label = symbol)) +\n  geom_point(size = 4, color = \"darkblue\") +\n  geom_text(nudge_y = 0.0005, fontface = \"bold\") +\n  labs(\n    title = \"Return vs Volatility (Risk–Return Tradeoff)\",\n    x = \"Volatility (Standard Deviation of Daily Return)\",\n    y = \"Mean Daily Return\"\n  ) +\n  scale_x_continuous(labels = scales::percent) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Step 1: Filter past 5 years only\nvolume_5yr &lt;- stock_data %&gt;%\n  filter(date &gt;= Sys.Date() %m-% years(5)) %&gt;%\n  mutate(\n    year = year(date),\n    month = month(date, label = TRUE)\n  ) %&gt;%\n  group_by(symbol, year, month) %&gt;%\n  summarise(total_volume = sum(volume, na.rm = TRUE), .groups = \"drop\")\n\n# Step 2: Plot barchart faceted by stock, grouped by year\nggplot(volume_5yr, aes(x = month, y = total_volume, fill = factor(year))) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ symbol, scales = \"free_y\") +\n  labs(\n    title = \"📊 Monthly Trading Volume by Stock (Past 5 Years)\",\n    x = \"Month\", y = \"Total Volume\",\n    fill = \"Year\"\n  ) +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Replace with user-defined stock selection\nstock_a &lt;- \"AMZN\"\nstock_b &lt;- \"TSLA\"\n\nrun_wilcoxon_test &lt;- function(stock_a, stock_b, data = stock_data) {\n  df &lt;- data %&gt;%\n    filter(symbol %in% c(stock_a, stock_b)) %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n  wilcox.test(daily_return ~ symbol, data = df)\n}\n\nrun_f_test &lt;- function(stock1, stock2, data = stock_data) {\n  df &lt;- data %&gt;%\n    filter(symbol %in% c(stock1, stock2)) %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n  var.test(daily_return ~ symbol, data = df)\n}\n\nObservation:\n\np-value = 0.6222 is much higher than 0.05 → So you fail to reject the null hypothesis.\nThere is no statistically significant difference in the median daily returns of AMZN and TSLA.\n\n\n\n\n\n# 📌 Simulated user input (replace with input$stock1 / input$stock2 in Shiny later)\nstock1 &lt;- \"AMZN\"\nstock2 &lt;- \"MSFT\"\n\nrun_variance_test &lt;- function(stock1, stock2, data = stock_data) {\n  # Step 1: Filter and prepare data\n  var_test_data &lt;- data %&gt;%\n    filter(symbol %in% c(stock1, stock2)) %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n  \n  # Step 2: Run F-Test\n  if (nrow(var_test_data) == 0) {\n    message(\"No data found for variance comparison between \", stock1, \" and \", stock2)\n    return(NULL)\n  }\n  \n  cat(\"📊 F-Test for Variance Comparison:\\n\")\n  cat(paste0(\"Comparing variance of daily returns: \", stock1, \" vs \", stock2, \"\\n\\n\"))\n  test_result &lt;- var.test(daily_return ~ symbol, data = var_test_data)\n  \n  return(test_result)\n}\n\nrun_variance_test(\"AMZN\", \"MSFT\")\n\n📊 F-Test for Variance Comparison:\nComparing variance of daily returns: AMZN vs MSFT\n\n\n\n    F test to compare two variances\n\ndata:  daily_return by symbol\nF = 1.9085, num df = 795, denom df = 795, p-value &lt; 2.2e-16\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.660663 2.193432\nsample estimates:\nratio of variances \n          1.908547 \n\n\n\n\n\n\nstock1 &lt;- \"AMZN\"\nstock2 &lt;- \"MSFT\"\n\nrun_correlation_test &lt;- function(stock1, stock2, data = stock_data) {\n  # Step 1: Filter and prepare data\n  cor_data &lt;- data %&gt;%\n    filter(symbol %in% c(stock1, stock2)) %&gt;%\n    select(symbol, date, daily_return) %&gt;%\n    filter(!is.na(daily_return)) %&gt;%\n    pivot_wider(names_from = symbol, values_from = daily_return)\n  \n  # Step 2: Check if both columns exist and have sufficient data\n  if (!(stock1 %in% names(cor_data)) | !(stock2 %in% names(cor_data))) {\n    message(\"❌ One or both stocks not available in daily_return data.\")\n    return(NULL)\n  }\n  \n  cor_data &lt;- cor_data %&gt;%\n    filter(!is.na(.data[[stock1]]), !is.na(.data[[stock2]]))\n  \n  if (nrow(cor_data) &lt; 10) {\n    message(\"⚠ Not enough data to compute correlation between \", stock1, \" and \", stock2)\n    return(NULL)\n  }\n  \n  # Step 3: Run correlation test\n  cat(\"📊 Pearson Correlation Test:\\n\")\n  cat(paste0(\"Testing daily return correlation: \", stock1, \" vs \", stock2, \"\\n\\n\"))\n  result &lt;- cor.test(cor_data[[stock1]], cor_data[[stock2]], method = \"pearson\")\n  return(result)\n}\n\nrun_correlation_test(\"AMZN\", \"MSFT\")\n\n📊 Pearson Correlation Test:\nTesting daily return correlation: AMZN vs MSFT\n\n\n\n    Pearson's product-moment correlation\n\ndata:  cor_data[[stock1]] and cor_data[[stock2]]\nt = 26.631, df = 794, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6483249 0.7219014\nsample estimates:\n     cor \n0.686869 \n\n\n\n\n\n\nrun_linear_regression &lt;- function(target_stock, market_index_stock, data = stock_data) {\n  # Step 1: Prepare dataset\n  reg_data &lt;- data %&gt;%\n    filter(symbol %in% c(target_stock, market_index_stock)) %&gt;%\n    select(date, symbol, daily_return, volume) %&gt;%\n    pivot_wider(names_from = symbol, values_from = c(daily_return, volume))\n\n  # Step 2: Construct dynamic column names\n  target_return_col &lt;- paste0(\"daily_return_\", target_stock)\n  target_volume_col &lt;- paste0(\"volume_\", target_stock)\n  market_return_col &lt;- paste0(\"daily_return_\", market_index_stock)\n\n  # Step 3: Rename for regression model\n  reg_data &lt;- reg_data %&gt;%\n    rename(\n      target_return = !!target_return_col,\n      target_volume = !!target_volume_col,\n      market_return = !!market_return_col\n    ) %&gt;%\n    filter(!is.na(target_return), !is.na(target_volume), !is.na(market_return))\n\n  # Step 4: Check if enough observations\n  if (nrow(reg_data) &lt; 10) {\n    message(\"⚠ Not enough data to run regression for \", target_stock)\n    return(NULL)\n  }\n\n  # Step 5: Run regression\n  cat(paste0(\"📊 Multiple Linear Regression: \", target_stock, \" ~ Volume + \", market_index_stock, \" Return\\n\\n\"))\n  model &lt;- lm(target_return ~ target_volume + market_return, data = reg_data)\n  return(summary(model))\n}\n\n\nrun_linear_regression(\"AMZN\", \"MSFT\")\n\n📊 Multiple Linear Regression: AMZN ~ Volume + MSFT Return\n\n\n\nCall:\nlm(formula = target_return ~ target_volume + market_return, data = reg_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.104250 -0.009906 -0.000143  0.008579  0.122908 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    7.658e-04  1.381e-03   0.555    0.579    \ntarget_volume -1.217e-11  2.157e-11  -0.564    0.573    \nmarket_return  9.487e-01  3.565e-02  26.611   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01733 on 793 degrees of freedom\nMultiple R-squared:  0.472, Adjusted R-squared:  0.4707 \nF-statistic: 354.4 on 2 and 793 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nrun_anova_test &lt;- function(data = stock_data) {\n  anova_data &lt;- data %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n\n  if (length(unique(anova_data$symbol)) &lt; 2) {\n    message(\"⚠ Not enough groups to run one-way ANOVA.\")\n    return(NULL)\n  }\n\n  anova_model &lt;- aov(daily_return ~ symbol, data = anova_data)\n\n  cat(\"📊 One-Way ANOVA: Daily Return ~ Stock Symbol\\n\\n\")\n  return(summary(anova_model))\n}\n\nrun_anova_test()\n\n📊 One-Way ANOVA: Daily Return ~ Stock Symbol\n\n\n              Df Sum Sq   Mean Sq F value Pr(&gt;F)\nsymbol         4 0.0027 0.0006765   0.859  0.488\nResiduals   3975 3.1315 0.0007878               \n\n\n\n\n\n\nrun_two_way_anova_test &lt;- function(data = stock_data) {\n  data &lt;- data %&gt;%\n    mutate(month = lubridate::month(date, label = TRUE))\n\n  anova2_data &lt;- data %&gt;%\n    select(symbol, daily_return, month) %&gt;%\n    filter(!is.na(daily_return))\n\n  if (length(unique(anova2_data$symbol)) &lt; 2 || length(unique(anova2_data$month)) &lt; 2) {\n    message(\"⚠ Not enough groups to run two-way ANOVA.\")\n    return(NULL)\n  }\n\n  anova2_model &lt;- aov(daily_return ~ symbol + month, data = anova2_data)\n\n  cat(\"📊 Two-Way ANOVA: Daily Return ~ Stock Symbol + Month\\n\\n\")\n  return(summary(anova2_model))\n}\n\n\nrun_two_way_anova_test()\n\n📊 Two-Way ANOVA: Daily Return ~ Stock Symbol + Month\n\n\n              Df Sum Sq   Mean Sq F value  Pr(&gt;F)   \nsymbol         4 0.0027 0.0006765   0.863 0.48536   \nmonth         11 0.0240 0.0021838   2.786 0.00129 **\nResiduals   3964 3.1075 0.0007839                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nrun_event_study &lt;- function(target_stock = \"NVDA\",\n                            market_index_stock = \"MSFT\",\n                            start_date = \"2020-01-01\",\n                            end_date = \"2022-12-31\") {\n  \n  # Step 1: Get data\n  event_stocks &lt;- unique(c(target_stock, market_index_stock))\n  event_stock_data &lt;- tq_get(event_stocks, from = start_date, to = end_date) %&gt;%\n    group_by(symbol) %&gt;%\n    arrange(date) %&gt;%\n    mutate(daily_return = adjusted / lag(adjusted) - 1) %&gt;%\n    ungroup()\n  \n  # Step 2: Pivot to wide format\n  event_df &lt;- event_stock_data %&gt;%\n    select(date, symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return)) %&gt;%\n    pivot_wider(names_from = symbol, values_from = daily_return)\n  \n  # Step 3: Rename dynamically\n  if (!target_stock %in% colnames(event_df) || !market_index_stock %in% colnames(event_df)) {\n    stop(\"❌ One or both selected stocks not available in event return data.\")\n  }\n\n  colnames(event_df)[which(colnames(event_df) == target_stock)] &lt;- \"target_return\"\n  colnames(event_df)[which(colnames(event_df) == market_index_stock)] &lt;- \"market_return\"\n  \n  # Step 4: OLS Regression for expected return\n  model &lt;- lm(target_return ~ market_return, data = event_df)\n  \n  # Step 5: Calculate abnormal returns & CAR\n  event_df$expected_return &lt;- predict(model, newdata = event_df)\n  event_df &lt;- event_df %&gt;%\n    mutate(\n      abnormal_return = target_return - expected_return,\n      CAR = cumsum(abnormal_return)\n    )\n  \n  # Step 6: Plot CAR\n  plot_ly(event_df, x = ~date, y = ~CAR, type = \"scatter\", mode = \"lines\",\n          line = list(color = \"darkblue\")) %&gt;%\n    layout(\n      title = paste0(target_stock, \" Cumulative Abnormal Return (\", start_date, \" to \", end_date, \")\"),\n      xaxis = list(title = \"Date\"),\n      yaxis = list(title = \"Cumulative Abnormal Return (CAR)\")\n    )\n}\n\nrun_event_study(\"AMZN\", \"MSFT\")           # Default COVID period\n\n\n\n\nrun_event_study(\"TSLA\", \"SPY\", \"2019-01-01\", \"2021-12-31\")  # Custom"
  },
  {
    "objectID": "Prototype/confirmatory_analysis.html#getting-started",
    "href": "Prototype/confirmatory_analysis.html#getting-started",
    "title": "Confirmatory Analysis",
    "section": "",
    "text": "We will load the following packages by using the pacman::p_load function:\ntidyquant, tidyverse, xts, timeDate, lubridate, writexl, broom, sandwich, lmtest, dplyr, tidyr, GGally, corrplot, zoo, plotly, scales, moments, gt, gtExtras\n\n\n\nOur stock data will be retrieved from Yahoo Finance using quantmod. In Shiny App, Data will be pulled real-time according to user’s selection. For now below data will be used to demonstrate EDA and CDA.\n\n\n\n\n# Simulate user portfolio (can be dynamic in Shiny later) \nuser_portfolio &lt;- data.frame(\n  symbol = c(\"AAPL\", \"MSFT\", \"TSLA\", \"NVDA\", \"AMZN\", \"NVDA\"),\n  buy_date = as.Date(c(\"2022-01-15\", \"2022-02-20\", \"2022-03-10\", \"2022-04-05\", \"2022-05-12\", \"2024-01-17\")),\n  quantity = c(10, 15, 5, 8, 12, 7)\n)\nuser_portfolio\n\n  symbol   buy_date quantity\n1   AAPL 2022-01-15       10\n2   MSFT 2022-02-20       15\n3   TSLA 2022-03-10        5\n4   NVDA 2022-04-05        8\n5   AMZN 2022-05-12       12\n6   NVDA 2024-01-17        7"
  },
  {
    "objectID": "Prototype/confirmatory_analysis.html#data-overview-eda",
    "href": "Prototype/confirmatory_analysis.html#data-overview-eda",
    "title": "Confirmatory Analysis",
    "section": "",
    "text": "In R Shiny, user will be able to select the stocks they have in their Portfolio. From the selected stocks, EDA will run accordingly.\n\n\n\nfang_returns &lt;- FANG %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    return = adjusted / lag(adjusted) - 1,\n    log_return = log(adjusted / lag(adjusted))\n  ) %&gt;%\n  ungroup()\n\n\n\n\nggplot(fang_returns, aes(x = return, fill = symbol)) +\n  geom_histogram(bins = 30, alpha = 0.6, position = \"identity\") +\n  labs(title = \"Histogram of Daily Returns by Stock\", x = \"Return\")\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(fang_returns, aes(x = symbol, y = return, fill = symbol)) +\n  geom_boxplot() +\n  labs(title = \"Return Distribution by Stock\")\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(fang_returns, aes(x = date, y = adjusted, color = symbol)) +\n  geom_line() +\n  labs(title = \"Adjusted Closing Price Over Time\", y = \"Adjusted Price\", x = \"Date\")\n\n\n\n\n\n\n\n\n\n\n\n\nfang_returns &lt;- fang_returns %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(rolling_vol_20 = rollapply(return, width = 20, FUN = sd, fill = NA, align = \"right\")) %&gt;%\n  ungroup()\n\nggplot(fang_returns %&gt;% filter(!is.na(rolling_vol_20)), \n       aes(x = date, y = rolling_vol_20, color = symbol)) +\n  geom_line() +\n  labs(title = \"20-Day Rolling Volatility\", y = \"Rolling Std Dev\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfang_returns %&gt;%\n  group_by(symbol) %&gt;%\n  summarise(\n    mean_return = mean(return, na.rm = TRUE),\n    sd_return = sd(return, na.rm = TRUE),\n    median_return = median(return, na.rm = TRUE),\n    min_return = min(return, na.rm = TRUE),\n    max_return = max(return, na.rm = TRUE),\n    sharpe_ratio = mean_return / sd_return,\n    skewness = skewness(return, na.rm = TRUE),\n    kurtosis = kurtosis(return, na.rm = TRUE)\n  )\n\n# A tibble: 4 × 9\n  symbol mean_return sd_return median_return min_return max_return sharpe_ratio\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n1 AMZN      0.00125     0.0194     0.000732     -0.110       0.141       0.0645\n2 GOOG      0.000861    0.0148     0.000134     -0.0532      0.161       0.0583\n3 META      0.00164     0.0220     0.00109      -0.0693      0.296       0.0744\n4 NFLX      0.00273     0.0324     0.0000796    -0.194       0.422       0.0841\n# ℹ 2 more variables: skewness &lt;dbl&gt;, kurtosis &lt;dbl&gt;\n\n\n\n\n\n\nfang_returns &lt;- fang_returns %&gt;%\n  group_by(symbol) %&gt;%\n  mutate(cumulative_return = cumprod(1 + coalesce(return, 0))) %&gt;%\n  ungroup()\n\nggplot(fang_returns, aes(x = date, y = cumulative_return, color = symbol)) +\n  geom_line() +\n  labs(title = \"Cumulative Returns\", y = \"Cumulative Return\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Pivot to wide format for correlation\nreturns_matrix &lt;- fang_returns %&gt;%\n  select(date, symbol, return) %&gt;%\n  pivot_wider(names_from = symbol, values_from = return)\n\nreturns_corr &lt;- cor(returns_matrix[,-1], use = \"pairwise.complete.obs\")\n\ncorrplot(returns_corr, method = \"color\", addCoef.col = \"black\", number.cex = 0.8, title = \"Return Correlation Matrix\")\n\n\n\n\n\n\n\n\n\n\n\nfang_stats &lt;- fang_returns %&gt;%\n  group_by(symbol) %&gt;%\n  summarise(mean_return = mean(return, na.rm = TRUE),\n            volatility = sd(return, na.rm = TRUE))\n\nggplot(fang_stats, aes(x = volatility, y = mean_return, label = symbol)) +\n  geom_point(size = 3) +\n  geom_text(nudge_y = 0.0005) +\n  labs(title = \"Return vs Volatility\", x = \"Volatility (Std Dev)\", y = \"Mean Return\")\n\n\n\n\n\n\n\n\nInteractive Plot\n\nplot_ly(fang_returns, x = ~date, y = ~adjusted, color = ~symbol, type = 'scatter', mode = 'lines')"
  },
  {
    "objectID": "Prototype/confirmatory_analysis.html#data-overview-cda",
    "href": "Prototype/confirmatory_analysis.html#data-overview-cda",
    "title": "Confirmatory Analysis",
    "section": "",
    "text": "# Replace with user-defined stock selection\nstock_a &lt;- \"AMZN\"\nstock_b &lt;- \"TSLA\"\n\nrun_wilcoxon_test &lt;- function(stock_a, stock_b, data = stock_data) {\n  df &lt;- data %&gt;%\n    filter(symbol %in% c(stock_a, stock_b)) %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n  wilcox.test(daily_return ~ symbol, data = df)\n}\n\nrun_f_test &lt;- function(stock1, stock2, data = stock_data) {\n  df &lt;- data %&gt;%\n    filter(symbol %in% c(stock1, stock2)) %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n  var.test(daily_return ~ symbol, data = df)\n}\n\nObservation:\n\np-value = 0.6222 is much higher than 0.05 → So you fail to reject the null hypothesis.\nThere is no statistically significant difference in the median daily returns of AMZN and TSLA.\n\n\n\n\n\n# 📌 Simulated user input (replace with input$stock1 / input$stock2 in Shiny later)\nstock1 &lt;- \"AMZN\"\nstock2 &lt;- \"MSFT\"\n\nrun_variance_test &lt;- function(stock1, stock2, data = stock_data) {\n  # Step 1: Filter and prepare data\n  var_test_data &lt;- data %&gt;%\n    filter(symbol %in% c(stock1, stock2)) %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n  \n  # Step 2: Run F-Test\n  if (nrow(var_test_data) == 0) {\n    message(\"No data found for variance comparison between \", stock1, \" and \", stock2)\n    return(NULL)\n  }\n  \n  cat(\"📊 F-Test for Variance Comparison:\\n\")\n  cat(paste0(\"Comparing variance of daily returns: \", stock1, \" vs \", stock2, \"\\n\\n\"))\n  test_result &lt;- var.test(daily_return ~ symbol, data = var_test_data)\n  \n  return(test_result)\n}\n\nrun_variance_test(\"AMZN\", \"MSFT\")\n\n📊 F-Test for Variance Comparison:\nComparing variance of daily returns: AMZN vs MSFT\n\n\n\n    F test to compare two variances\n\ndata:  daily_return by symbol\nF = 1.9085, num df = 795, denom df = 795, p-value &lt; 2.2e-16\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.660663 2.193432\nsample estimates:\nratio of variances \n          1.908547 \n\n\n\n\n\n\nstock1 &lt;- \"AMZN\"\nstock2 &lt;- \"MSFT\"\n\nrun_correlation_test &lt;- function(stock1, stock2, data = stock_data) {\n  # Step 1: Filter and prepare data\n  cor_data &lt;- data %&gt;%\n    filter(symbol %in% c(stock1, stock2)) %&gt;%\n    select(symbol, date, daily_return) %&gt;%\n    filter(!is.na(daily_return)) %&gt;%\n    pivot_wider(names_from = symbol, values_from = daily_return)\n  \n  # Step 2: Check if both columns exist and have sufficient data\n  if (!(stock1 %in% names(cor_data)) | !(stock2 %in% names(cor_data))) {\n    message(\"❌ One or both stocks not available in daily_return data.\")\n    return(NULL)\n  }\n  \n  cor_data &lt;- cor_data %&gt;%\n    filter(!is.na(.data[[stock1]]), !is.na(.data[[stock2]]))\n  \n  if (nrow(cor_data) &lt; 10) {\n    message(\"⚠ Not enough data to compute correlation between \", stock1, \" and \", stock2)\n    return(NULL)\n  }\n  \n  # Step 3: Run correlation test\n  cat(\"📊 Pearson Correlation Test:\\n\")\n  cat(paste0(\"Testing daily return correlation: \", stock1, \" vs \", stock2, \"\\n\\n\"))\n  result &lt;- cor.test(cor_data[[stock1]], cor_data[[stock2]], method = \"pearson\")\n  return(result)\n}\n\nrun_correlation_test(\"AMZN\", \"MSFT\")\n\n📊 Pearson Correlation Test:\nTesting daily return correlation: AMZN vs MSFT\n\n\n\n    Pearson's product-moment correlation\n\ndata:  cor_data[[stock1]] and cor_data[[stock2]]\nt = 26.631, df = 794, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6483249 0.7219014\nsample estimates:\n     cor \n0.686869 \n\n\n\n\n\n\nrun_linear_regression &lt;- function(target_stock, market_index_stock, data = stock_data) {\n  # Step 1: Prepare dataset\n  reg_data &lt;- data %&gt;%\n    filter(symbol %in% c(target_stock, market_index_stock)) %&gt;%\n    select(date, symbol, daily_return, volume) %&gt;%\n    pivot_wider(names_from = symbol, values_from = c(daily_return, volume))\n\n  # Step 2: Construct dynamic column names\n  target_return_col &lt;- paste0(\"daily_return_\", target_stock)\n  target_volume_col &lt;- paste0(\"volume_\", target_stock)\n  market_return_col &lt;- paste0(\"daily_return_\", market_index_stock)\n\n  # Step 3: Rename for regression model\n  reg_data &lt;- reg_data %&gt;%\n    rename(\n      target_return = !!target_return_col,\n      target_volume = !!target_volume_col,\n      market_return = !!market_return_col\n    ) %&gt;%\n    filter(!is.na(target_return), !is.na(target_volume), !is.na(market_return))\n\n  # Step 4: Check if enough observations\n  if (nrow(reg_data) &lt; 10) {\n    message(\"⚠ Not enough data to run regression for \", target_stock)\n    return(NULL)\n  }\n\n  # Step 5: Run regression\n  cat(paste0(\"📊 Multiple Linear Regression: \", target_stock, \" ~ Volume + \", market_index_stock, \" Return\\n\\n\"))\n  model &lt;- lm(target_return ~ target_volume + market_return, data = reg_data)\n  return(summary(model))\n}\n\n\nrun_linear_regression(\"AMZN\", \"MSFT\")\n\n📊 Multiple Linear Regression: AMZN ~ Volume + MSFT Return\n\n\n\nCall:\nlm(formula = target_return ~ target_volume + market_return, data = reg_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.104250 -0.009906 -0.000143  0.008579  0.122908 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    7.658e-04  1.381e-03   0.555    0.579    \ntarget_volume -1.217e-11  2.157e-11  -0.564    0.573    \nmarket_return  9.487e-01  3.565e-02  26.611   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01733 on 793 degrees of freedom\nMultiple R-squared:  0.472, Adjusted R-squared:  0.4707 \nF-statistic: 354.4 on 2 and 793 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nrun_anova_test &lt;- function(data = stock_data) {\n  anova_data &lt;- data %&gt;%\n    select(symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return))\n\n  if (length(unique(anova_data$symbol)) &lt; 2) {\n    message(\"⚠ Not enough groups to run one-way ANOVA.\")\n    return(NULL)\n  }\n\n  anova_model &lt;- aov(daily_return ~ symbol, data = anova_data)\n\n  cat(\"📊 One-Way ANOVA: Daily Return ~ Stock Symbol\\n\\n\")\n  return(summary(anova_model))\n}\n\nrun_anova_test()\n\n📊 One-Way ANOVA: Daily Return ~ Stock Symbol\n\n\n              Df Sum Sq   Mean Sq F value Pr(&gt;F)\nsymbol         4 0.0027 0.0006765   0.859  0.488\nResiduals   3975 3.1315 0.0007878               \n\n\n\n\n\n\nrun_two_way_anova_test &lt;- function(data = stock_data) {\n  data &lt;- data %&gt;%\n    mutate(month = lubridate::month(date, label = TRUE))\n\n  anova2_data &lt;- data %&gt;%\n    select(symbol, daily_return, month) %&gt;%\n    filter(!is.na(daily_return))\n\n  if (length(unique(anova2_data$symbol)) &lt; 2 || length(unique(anova2_data$month)) &lt; 2) {\n    message(\"⚠ Not enough groups to run two-way ANOVA.\")\n    return(NULL)\n  }\n\n  anova2_model &lt;- aov(daily_return ~ symbol + month, data = anova2_data)\n\n  cat(\"📊 Two-Way ANOVA: Daily Return ~ Stock Symbol + Month\\n\\n\")\n  return(summary(anova2_model))\n}\n\n\nrun_two_way_anova_test()\n\n📊 Two-Way ANOVA: Daily Return ~ Stock Symbol + Month\n\n\n              Df Sum Sq   Mean Sq F value  Pr(&gt;F)   \nsymbol         4 0.0027 0.0006765   0.863 0.48536   \nmonth         11 0.0240 0.0021838   2.786 0.00129 **\nResiduals   3964 3.1075 0.0007839                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\nrun_event_study &lt;- function(target_stock = \"NVDA\",\n                            market_index_stock = \"MSFT\",\n                            start_date = \"2020-01-01\",\n                            end_date = \"2022-12-31\") {\n  \n  # Step 1: Get data\n  event_stocks &lt;- unique(c(target_stock, market_index_stock))\n  event_stock_data &lt;- tq_get(event_stocks, from = start_date, to = end_date) %&gt;%\n    group_by(symbol) %&gt;%\n    arrange(date) %&gt;%\n    mutate(daily_return = adjusted / lag(adjusted) - 1) %&gt;%\n    ungroup()\n  \n  # Step 2: Pivot to wide format\n  event_df &lt;- event_stock_data %&gt;%\n    select(date, symbol, daily_return) %&gt;%\n    filter(!is.na(daily_return)) %&gt;%\n    pivot_wider(names_from = symbol, values_from = daily_return)\n  \n  # Step 3: Rename dynamically\n  if (!target_stock %in% colnames(event_df) || !market_index_stock %in% colnames(event_df)) {\n    stop(\"❌ One or both selected stocks not available in event return data.\")\n  }\n\n  colnames(event_df)[which(colnames(event_df) == target_stock)] &lt;- \"target_return\"\n  colnames(event_df)[which(colnames(event_df) == market_index_stock)] &lt;- \"market_return\"\n  \n  # Step 4: OLS Regression for expected return\n  model &lt;- lm(target_return ~ market_return, data = event_df)\n  \n  # Step 5: Calculate abnormal returns & CAR\n  event_df$expected_return &lt;- predict(model, newdata = event_df)\n  event_df &lt;- event_df %&gt;%\n    mutate(\n      abnormal_return = target_return - expected_return,\n      CAR = cumsum(abnormal_return)\n    )\n  \n  # Step 6: Plot CAR\n  plot_ly(event_df, x = ~date, y = ~CAR, type = \"scatter\", mode = \"lines\",\n          line = list(color = \"darkblue\")) %&gt;%\n    layout(\n      title = paste0(target_stock, \" Cumulative Abnormal Return (\", start_date, \" to \", end_date, \")\"),\n      xaxis = list(title = \"Date\"),\n      yaxis = list(title = \"Cumulative Abnormal Return (CAR)\")\n    )\n}\n\nrun_event_study(\"AMZN\", \"MSFT\")           # Default COVID period\n\n\n\n\nrun_event_study(\"TSLA\", \"SPY\", \"2019-01-01\", \"2021-12-31\")  # Custom"
  },
  {
    "objectID": "Scratch/Scratch.html",
    "href": "Scratch/Scratch.html",
    "title": "Scratch",
    "section": "",
    "text": "pacman::p_load(tidyquant, tidyverse, xts, timeDate, lubridate, writexl, broom, sandwich, lmtest, dplyr, tidyr, GGally)\n\n\ndata(FANG, package=\"tidyquant\")\n\n\n# show the first 5 rows\nFANG %&gt;% slice(1:5)\n\n# A tibble: 5 × 8\n  symbol date        open  high   low close   volume adjusted\n  &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 META   2013-01-02  27.4  28.2  27.4  28   69846400     28  \n2 META   2013-01-03  27.9  28.5  27.6  27.8 63140600     27.8\n3 META   2013-01-04  28.0  28.9  27.8  28.8 72715400     28.8\n4 META   2013-01-07  28.7  29.8  28.6  29.4 83781800     29.4\n5 META   2013-01-08  29.5  29.6  28.9  29.1 45871300     29.1\n\ntbs1 &lt;- tibble(\n  Date = seq(as.Date(\"2017-01-01\"), length=3, by=\"months\"),\n  returns = rnorm(3),\n  letters = sample(letters, 3, replace = TRUE)\n)\n\ntbs1\n\n# A tibble: 3 × 3\n  Date       returns letters\n  &lt;date&gt;       &lt;dbl&gt; &lt;chr&gt;  \n1 2017-01-01  -1.71  t      \n2 2017-02-01   0.966 a      \n3 2017-03-01   0.863 v      \n\n\n\n# extract the returns column as vector\ntbs1$returns\n\n[1] -1.7119117  0.9655451  0.8628949\n\ntbs1 %&gt;% pull(returns)\n\n[1] -1.7119117  0.9655451  0.8628949\n\ntbs1[[2]]\n\n[1] -1.7119117  0.9655451  0.8628949\n\ntbs1 %&gt;% .[[2]]\n\n[1] -1.7119117  0.9655451  0.8628949\n\n\n\n# vreate temporary file\ntmp &lt;- tempfile(fileext = \".csv\")\n\nwrite_csv(tbs1,file = tmp)\n\ntbs1b &lt;- read_csv(tmp)\n\nRows: 3 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): letters\ndbl  (1): returns\ndate (1): Date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndplyr::all_equal(tbs1,tbs1b) # only the factor levels differ\n\nWarning: `all_equal()` was deprecated in dplyr 1.1.0.\nℹ Please use `all.equal()` instead.\nℹ And manually order the rows/cols as needed\n\n\n[1] \"- Rows in x but not in y: 1\\n- Rows in y but not in x: 1\\n\"\n\n\n\n# temporary file name\ntmp &lt;- tempfile(fileext = \".xlsx\")\n\n# write to Excel file\nwritexl::write_xlsx(FANG,path = tmp)\n\n# read from Excel file and transform to date using mutate\nFANG3 &lt;- readxl::read_xlsx(tmp) %&gt;% mutate(date=as.Date(date))\n\n# check whether both datasets are similar\ndplyr::all_equal(FANG,FANG3) \n\n[1] TRUE\n\n\n\n# data dimensions\ndim(FANG)\n\n[1] 4032    8\n\n# names\nnames(FANG)\n\n[1] \"symbol\"   \"date\"     \"open\"     \"high\"     \"low\"      \"close\"    \"volume\"  \n[8] \"adjusted\"\n\n# carefully inspect the data\nglimpse(FANG)\n\nRows: 4,032\nColumns: 8\n$ symbol   &lt;chr&gt; \"META\", \"META\", \"META\", \"META\", \"META\", \"META\", \"META\", \"META…\n$ date     &lt;date&gt; 2013-01-02, 2013-01-03, 2013-01-04, 2013-01-07, 2013-01-08, …\n$ open     &lt;dbl&gt; 27.44, 27.88, 28.01, 28.69, 29.51, 29.67, 30.60, 31.28, 32.08…\n$ high     &lt;dbl&gt; 28.18, 28.47, 28.93, 29.79, 29.60, 30.60, 31.45, 31.96, 32.21…\n$ low      &lt;dbl&gt; 27.42, 27.59, 27.83, 28.65, 28.86, 29.49, 30.28, 31.10, 30.62…\n$ close    &lt;dbl&gt; 28.00, 27.77, 28.76, 29.42, 29.06, 30.59, 31.30, 31.72, 30.95…\n$ volume   &lt;dbl&gt; 69846400, 63140600, 72715400, 83781800, 45871300, 104787700, …\n$ adjusted &lt;dbl&gt; 28.00, 27.77, 28.76, 29.42, 29.06, 30.59, 31.30, 31.72, 30.95…\n\n\n\n# information on the first three variables\nFANG %&gt;% select(symbol,date,open) %&gt;% summary()\n\n    symbol               date                 open        \n Length:4032        Min.   :2013-01-02   Min.   :  22.99  \n Class :character   1st Qu.:2014-01-01   1st Qu.: 106.31  \n Mode  :character   Median :2015-01-01   Median : 335.67  \n                    Mean   :2015-01-01   Mean   : 382.70  \n                    3rd Qu.:2016-01-01   3rd Qu.: 581.47  \n                    Max.   :2016-12-30   Max.   :1226.80  \n\n\n\n# arrange, filter, mutate\nFANG_ret &lt;- FANG %&gt;% group_by(symbol) %&gt;% select(symbol,date,adjusted) %&gt;%\n  arrange(date) %&gt;%\n  filter(date&gt;\"2016-06-30\") %&gt;%\n  mutate(return=adjusted/dplyr::lag(adjusted)-1) \n# show\nFANG_ret %&gt;% slice(1:2)\n\n# A tibble: 8 × 4\n# Groups:   symbol [4]\n  symbol date       adjusted     return\n  &lt;chr&gt;  &lt;date&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1 AMZN   2016-07-01    726.  NA        \n2 AMZN   2016-07-05    728.   0.00333  \n3 GOOG   2016-07-01    699.  NA        \n4 GOOG   2016-07-05    695.  -0.00609  \n5 META   2016-07-01    114.  NA        \n6 META   2016-07-05    114.   0.0000875\n7 NFLX   2016-07-01     96.7 NA        \n8 NFLX   2016-07-05     97.9  0.0128"
  },
  {
    "objectID": "Scratch/Scratch.html#regression",
    "href": "Scratch/Scratch.html#regression",
    "title": "Scratch",
    "section": "Regression",
    "text": "Regression\n\nFANG_ret2 &lt;- FANG_ret %&gt;% ungroup() %&gt;%\n  left_join(FANG_ret %&gt;% group_by(date) %&gt;% summarise(index=mean(return)),by=\"date\") %&gt;%\n  select(symbol,date,return,index)\nFANG_ret2 %&gt;% group_by(symbol) %&gt;% slice(1:2)\n\n# A tibble: 8 × 4\n# Groups:   symbol [4]\n  symbol date           return    index\n  &lt;chr&gt;  &lt;date&gt;          &lt;dbl&gt;    &lt;dbl&gt;\n1 AMZN   2016-07-01 NA         NA      \n2 AMZN   2016-07-05  0.00333    0.00254\n3 GOOG   2016-07-01 NA         NA      \n4 GOOG   2016-07-05 -0.00609    0.00254\n5 META   2016-07-01 NA         NA      \n6 META   2016-07-05  0.0000875  0.00254\n7 NFLX   2016-07-01 NA         NA      \n8 NFLX   2016-07-05  0.0128     0.00254\n\n\n\nFANG_ret2n &lt;- FANG_ret2 %&gt;% nest_by(symbol)\nFANG_ret2n\n\n# A tibble: 4 × 2\n# Rowwise:  symbol\n  symbol               data\n  &lt;chr&gt;  &lt;list&lt;tibble[,3]&gt;&gt;\n1 AMZN            [127 × 3]\n2 GOOG            [127 × 3]\n3 META            [127 × 3]\n4 NFLX            [127 × 3]\n\n\n\nFANG_reg &lt;- FANG_ret2n %&gt;%\n  mutate(model = list(lm(return ~ index, data = data)))\nFANG_reg\n\n# A tibble: 4 × 3\n# Rowwise:  symbol\n  symbol               data model \n  &lt;chr&gt;  &lt;list&lt;tibble[,3]&gt;&gt; &lt;list&gt;\n1 AMZN            [127 × 3] &lt;lm&gt;  \n2 GOOG            [127 × 3] &lt;lm&gt;  \n3 META            [127 × 3] &lt;lm&gt;  \n4 NFLX            [127 × 3] &lt;lm&gt;  \n\n\n\nFANG_reg %&gt;%\n  summarize(tidy(model))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'symbol'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 6\n# Groups:   symbol [4]\n  symbol term         estimate std.error statistic  p.value\n  &lt;chr&gt;  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 AMZN   (Intercept) -0.000389  0.000807    -0.482 6.30e- 1\n2 AMZN   index        0.810     0.0716      11.3   8.01e-21\n3 GOOG   (Intercept)  0.000253  0.000591     0.428 6.70e- 1\n4 GOOG   index        0.642     0.0524      12.2   4.60e-23\n5 META   (Intercept) -0.000525  0.000782    -0.672 5.03e- 1\n6 META   index        0.727     0.0694      10.5   8.76e-19\n7 NFLX   (Intercept)  0.000662  0.00151      0.439 6.61e- 1\n8 NFLX   index        1.82      0.134       13.6   2.35e-26\n\n\n\nFANG_reg %&gt;%\n  summarize(glance(model))\n\n`summarise()` has grouped output by 'symbol'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 4 × 13\n# Groups:   symbol [4]\n  symbol r.squared adj.r.squared   sigma statistic  p.value    df logLik   AIC\n  &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 AMZN       0.508         0.504 0.00903      128. 8.01e-21     1   415. -825.\n2 GOOG       0.547         0.543 0.00661      150. 4.60e-23     1   455. -903.\n3 META       0.470         0.465 0.00875      110. 8.76e-19     1   419. -832.\n4 NFLX       0.599         0.596 0.0169       185. 2.35e-26     1   337. -667.\n# ℹ 4 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nFANG_ret2n %&gt;%\n  mutate(model = list(bind_rows(coef(lm(return ~ index, data = data))))) %&gt;%\n  unnest(model)\n\n# A tibble: 4 × 4\n# Groups:   symbol [4]\n  symbol               data `(Intercept)` index\n  &lt;chr&gt;  &lt;list&lt;tibble[,3]&gt;&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 AMZN            [127 × 3]     -0.000389 0.810\n2 GOOG            [127 × 3]      0.000253 0.642\n3 META            [127 × 3]     -0.000525 0.727\n4 NFLX            [127 × 3]      0.000662 1.82 \n\n\n\nFANG_reg %&gt;%\n  mutate(ci=list(as_tibble(confint(model),rownames=\"coef\"))) %&gt;%\n  unnest(ci) %&gt;% select(-data,-model)\n\n# A tibble: 8 × 4\n# Groups:   symbol [4]\n  symbol coef          `2.5 %` `97.5 %`\n  &lt;chr&gt;  &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;\n1 AMZN   (Intercept) -0.00199   0.00121\n2 AMZN   index        0.669     0.952  \n3 GOOG   (Intercept) -0.000917  0.00142\n4 GOOG   index        0.538     0.745  \n5 META   (Intercept) -0.00207   0.00102\n6 META   index        0.590     0.865  \n7 NFLX   (Intercept) -0.00232   0.00365\n8 NFLX   index        1.56      2.09   \n\n\n\nFANG_reg %&gt;%\n  mutate(lmHC = list(coeftest(model, vcov. = vcovHC(model, type = \"HC1\")))) %&gt;%\n  reframe(broom::tidy(lmHC), .groups = \"drop\")\n\n# A tibble: 8 × 7\n  symbol term         estimate std.error statistic  p.value .groups\n  &lt;chr&gt;  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;  \n1 AMZN   (Intercept) -0.000389  0.000787    -0.495 6.22e- 1 drop   \n2 AMZN   index        0.810     0.161        5.04  1.60e- 6 drop   \n3 GOOG   (Intercept)  0.000253  0.000582     0.434 6.65e- 1 drop   \n4 GOOG   index        0.642     0.0847       7.57  7.35e-12 drop   \n5 META   (Intercept) -0.000525  0.000790    -0.665 5.07e- 1 drop   \n6 META   index        0.727     0.147        4.94  2.47e- 6 drop   \n7 NFLX   (Intercept)  0.000662  0.00146      0.455 6.50e- 1 drop   \n8 NFLX   index        1.82      0.361        5.04  1.58e- 6 drop"
  },
  {
    "objectID": "Scratch/Scratch.html#plotting",
    "href": "Scratch/Scratch.html#plotting",
    "title": "Scratch",
    "section": "Plotting",
    "text": "Plotting\n\nFANG_ret %&gt;% ggplot(aes(symbol, return)) + geom_boxplot(aes(color=symbol)) + \n  labs(x=\"symbols\", y=\"returns\")\n\nWarning: Removed 4 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\nFANG_ret %&gt;%\n  filter(is.finite(return)) %&gt;%\n  ggplot(aes(x = return)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 0.01, fill = \"skyblue\", color = \"black\") +\n  geom_density(lwd = 1, color = \"darkblue\") +\n  facet_wrap(~symbol, scales = \"free\") +\n  xlab(\"Return\") +\n  ggtitle(\"Distribution of Returns by Stock Symbol\")\n\n\n\n\n\n\n\n\n\np &lt;- FANG_ret %&gt;%\n  ungroup() %&gt;%\n  select(date, return, symbol) %&gt;%\n  pivot_wider(id_cols = date, names_from = symbol, values_from = return) %&gt;%\n  filter(if_all(-date, ~ is.finite(.) & !is.na(.))) %&gt;%\n  select(-date) %&gt;%\n  ggpairs()\n\np\n\n\n\n\n\n\n\n\n\ntq_exchange_options()\n\n[1] \"AMEX\"   \"NASDAQ\" \"NYSE\"  \n\n\n\namex &lt;- tq_exchange(\"AMEX\")\n\nGetting data...\n\n\nWarning: Failed to retrieve data for exchange 'amex'. Failed to perform HTTP\nrequest.\n\nsaveRDS(amex, \"amex_data.rds\")\n\nnasdaq &lt;- tq_exchange(\"NASDAQ\")\n\nGetting data...\n\n\nWarning: Failed to retrieve data for exchange 'nasdaq'. Failed to perform HTTP\nrequest.\n\nsaveRDS(nasdaq, \"nasdaq_data.rds\")\n\nnyse &lt;- tq_exchange(\"NYSE\")\n\nGetting data...\n\n\nWarning: Failed to retrieve data for exchange 'nyse'. Failed to perform HTTP\nrequest.\n\nsaveRDS(nyse, \"nyse_data.rds\")"
  },
  {
    "objectID": "Prototype/confirmatory_analysis.html#data-overview-exploratory-data-analysis",
    "href": "Prototype/confirmatory_analysis.html#data-overview-exploratory-data-analysis",
    "title": "Confirmatory Analysis",
    "section": "",
    "text": "In R Shiny, user will be able to select the stocks they have in their Portfolio. From the selected stocks, EDA will run accordingly.\n\n\n\nIn R Shiny, user will be able to select the stocks they have in their Portfolio. From the selected stocks, EDA will run accordingly.\n\n\n\n# 📦 Function: Prepare User Portfolio Input\ntidy_user_portfolio &lt;- function() {\n  data.frame(\n    symbol = c(\"AAPL\", \"MSFT\", \"TSLA\", \"NVDA\", \"AMZN\", \"NVDA\"),\n    buy_date = as.Date(c(\"2022-01-15\", \"2022-02-20\", \"2022-03-10\", \"2022-04-05\", \"2022-05-12\", \"2024-01-17\")),\n    quantity = c(10, 15, 5, 8, 12, 7),\n    buy_price = c(NA, 287, NA, 26, NA, 55)\n  )\n}\n\n\n\n\n\n\n# 📈 Pull Stock Data\nget_stock_data &lt;- function(user_portfolio) {\n  data_start &lt;- min(user_portfolio$buy_date, na.rm = TRUE)\n  stock_data_raw &lt;- tq_get(unique(user_portfolio$symbol), from = data_start, to = Sys.Date())\n\n  stock_data &lt;- stock_data_raw %&gt;%\n    group_by(symbol, date) %&gt;%\n    summarise(\n      open = first(open),\n      high = max(high, na.rm = TRUE),\n      low = min(low, na.rm = TRUE),\n      close = last(close),\n      volume = sum(volume, na.rm = TRUE),\n      adjusted = last(adjusted),\n      .groups = \"drop\"\n    )\n\n  return(stock_data)\n}\n\n\n# Initialize storage lists\ntrack_portfolio_returns &lt;- function(user_portfolio, stock_data) {\n  portfolio_results &lt;- list()\n  summary_list &lt;- list()\n  skipped_stocks &lt;- c()\n\n  for (i in 1:nrow(user_portfolio)) {\n    stock &lt;- user_portfolio$symbol[i]\n    buy_date_input &lt;- user_portfolio$buy_date[i]\n    qty &lt;- user_portfolio$quantity[i]\n    buy_price_user &lt;- user_portfolio$buy_price[i]\n\n    stock_prices &lt;- stock_data %&gt;% filter(symbol == stock)\n    available_dates &lt;- stock_prices$date\n    valid_buy_date &lt;- max(available_dates[available_dates &lt;= buy_date_input])\n\n    if (is.infinite(valid_buy_date) | is.na(valid_buy_date)) {\n      warning(paste(\"No available trading date before\", buy_date_input, \"for\", stock, \"- skipping...\"))\n      skipped_stocks &lt;- c(skipped_stocks, stock)\n      next\n    }\n\n    day_row &lt;- stock_prices %&gt;% filter(date == valid_buy_date)\n    day_high &lt;- max(day_row$high, na.rm = TRUE)\n    day_low  &lt;- min(day_row$low, na.rm = TRUE)\n    median_price &lt;- median(day_row$adjusted, na.rm = TRUE)\n\n    if (is.na(median_price) || median_price == 0) {\n      warning(paste(\"⚠ No valid price data on\", valid_buy_date, \"for\", stock, \"- skipping...\"))\n      next\n    }\n\n    if (!is.na(buy_price_user)) {\n      buy_price &lt;- buy_price_user\n      buy_price_source &lt;- \"User Input\"\n      price_out_of_range &lt;- buy_price &lt; day_low | buy_price &gt; day_high\n      if (price_out_of_range) {\n        warning(paste0(\"⚠ BUY PRICE OUT OF RANGE for \", stock, \": $\", round(buy_price_user, 2),\n                       \" is outside [$\", round(day_low, 2), \" – $\", round(day_high, 2), \"] on \", valid_buy_date))\n      }\n    } else {\n      buy_price &lt;- median_price\n      buy_price_source &lt;- \"Median Price\"\n      price_out_of_range &lt;- FALSE\n    }\n\n    tracking_data &lt;- stock_prices %&gt;%\n      filter(date &gt;= valid_buy_date) %&gt;%\n      arrange(date) %&gt;%\n      mutate(\n        return_since_buy = (adjusted / buy_price) - 1,\n        current_value = adjusted * qty,\n        stock = stock,\n        buy_date = valid_buy_date,\n        quantity = qty,\n        buy_price = buy_price,\n        invested_amount = buy_price * qty,\n        holding_value = adjusted * qty,\n        unrealized_return = (adjusted - buy_price) * qty,\n        position_id = paste0(stock, \"_\", valid_buy_date)\n      )\n\n    portfolio_results[[i]] &lt;- tracking_data\n\n    summary_list[[i]] &lt;- tibble(\n      stock = stock,\n      buy_date = valid_buy_date,\n      quantity = qty,\n      buy_price = buy_price,\n      buy_price_source = buy_price_source,\n      day_low = day_low,\n      day_high = day_high,\n      price_out_of_range = price_out_of_range,\n      invested_amount = buy_price * qty,\n      current_price = tail(tracking_data$adjusted, 1),\n      current_value = tail(tracking_data$holding_value, 1),\n      unrealized_return = tail(tracking_data$unrealized_return, 1),\n      return_percent = tail(tracking_data$return_since_buy, 1)\n    )\n  }\n\n  list(\n    portfolio_tracking_all = bind_rows(portfolio_results),\n    portfolio_summary = bind_rows(summary_list),\n    skipped_stocks = skipped_stocks\n  )\n}\n\n\n\n\n# Clean summary\ngenerate_portfolio_summary &lt;- function(portfolio_summary) {\n  portfolio_summary_clean &lt;- portfolio_summary %&gt;%\n    mutate(\n      `Buy Price Status` = case_when(\n        is.na(price_out_of_range) ~ \"N/A\",\n        price_out_of_range ~ \"❌ Out of Range\",\n        TRUE ~ \"✔ OK\"\n      ),\n      `Return (%)` = percent(return_percent),\n      `Unrealized Return ($)` = dollar(unrealized_return)\n    ) %&gt;%\n    select(\n      Stock = stock,\n      `Buy Date` = buy_date,\n      Quantity = quantity,\n      `Buy Price ($)` = buy_price,\n      `Price Source` = buy_price_source,\n      `Day Low ($)` = day_low,\n      `Day High ($)` = day_high,\n      `Buy Price Status`,\n      `Invested Amount ($)` = invested_amount,\n      `Current Price ($)` = current_price,\n      `Current Value ($)` = current_value,\n      `Unrealized Return ($)`,\n      `Return (%)`\n    )\n\n  # 📊 Return GT Table\n  portfolio_summary_clean %&gt;%\n    gt() %&gt;%\n    tab_header(title = \"📊 Portfolio Summary with % and $ Return\") %&gt;%\n    fmt_currency(columns = c(\n      `Buy Price ($)`, `Day Low ($)`, `Day High ($)`,\n      `Invested Amount ($)`, `Current Price ($)`, `Current Value ($)`\n    )) %&gt;%\n    data_color(\n      columns = `Buy Price Status`,\n      fn = function(x) ifelse(x == \"❌ Out of Range\", \"tomato\", \"lightgreen\")\n    )\n}\n\n\n\n\n\n\n# Step 1: Simulate or get user portfolio\nuser_portfolio &lt;- tidy_user_portfolio()\n\n# Step 2: Pull stock data\nstock_data &lt;- get_stock_data(user_portfolio)\n\n# Step 3: Track portfolio returns\nportfolio_output &lt;- track_portfolio_returns(user_portfolio, stock_data)\n\nWarning in max.default(structure(numeric(0), class = \"Date\"), na.rm = FALSE):\nno non-missing arguments to max; returning -Inf\n\n\nWarning in track_portfolio_returns(user_portfolio, stock_data): No available\ntrading date before 2022-01-15 for AAPL - skipping...\n\n# Extract outputs from the list\nportfolio_tracking_all &lt;- portfolio_output$portfolio_tracking_all\nportfolio_summary &lt;- portfolio_output$portfolio_summary\nskipped_stocks &lt;- portfolio_output$skipped_stocks\n\n\n\n\n\nif (length(skipped_stocks) &gt; 0) {\n  message(\"⚠ Skipped Stocks: \", paste(skipped_stocks, collapse = \", \"))\n}\n\n⚠ Skipped Stocks: AAPL\n\n\n\n\n\n\n# Step 4: Show portfolio summary table (rendered using gt)\ngenerate_portfolio_summary(portfolio_summary)\n\n\n\n\n\n\n\n📊 Portfolio Summary with % and $ Return\n\n\nStock\nBuy Date\nQuantity\nBuy Price ($)\nPrice Source\nDay Low ($)\nDay High ($)\nBuy Price Status\nInvested Amount ($)\nCurrent Price ($)\nCurrent Value ($)\nUnrealized Return ($)\nReturn (%)\n\n\n\n\nMSFT\n2022-02-18\n15\n$287.00\nUser Input\n$286.31\n$293.86\n✔ OK\n$4,305.00\n$391.26\n$5,868.90\n$1,563.90\n36%\n\n\nTSLA\n2022-03-10\n5\n$279.43\nMedian Price\n$270.12\n$284.82\n✔ OK\n$1,397.17\n$248.71\n$1,243.55\n-$153.62\n-11%\n\n\nNVDA\n2022-04-05\n8\n$26.00\nUser Input\n$25.82\n$27.32\n✔ OK\n$208.00\n$117.70\n$941.60\n$733.60\n353%\n\n\nAMZN\n2022-05-12\n12\n$106.93\nMedian Price\n$102.41\n$110.78\n✔ OK\n$1,283.17\n$196.21\n$2,354.52\n$1,071.35\n83%\n\n\nNVDA\n2024-01-17\n7\n$55.00\nUser Input\n$54.74\n$56.47\n✔ OK\n$385.00\n$117.70\n$823.90\n$438.90\n114%\n\n\n\n\n\n\n\n\n\n\n\nggplot(portfolio_tracking_all, aes(x = date, y = return_since_buy, color = position_id)) +\n  geom_line(size = 1) +\n  labs(title = \"Cumulative Return Since Buy Date (By Position)\", y = \"Return\", x = \"Date\") +\n  scale_y_continuous(labels = scales::percent)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(\n  data = portfolio_tracking_all,\n  x = ~date,\n  y = ~holding_value,\n  color = ~position_id,\n  type = 'scatter',\n  mode = 'lines',\n  text = ~paste0(\n    \"Stock: \", stock, \"&lt;br&gt;\",\n    \"Buy Date: \", buy_date, \"&lt;br&gt;\",\n    \"Date: \", format(date, \"%Y-%m-%d\"), \"&lt;br&gt;\",\n    \"Value: $\", format(round(holding_value, 2), big.mark = \",\")\n  ),\n  hoverinfo = \"text\"\n) %&gt;%\n  layout(\n    title = \"Individual Stock Value Over Time (By Buy-in Position)\",\n    xaxis = list(title = \"Date\"),\n    yaxis = list(title = \"Holding Value (USD)\")\n  )\n\n\n\n\n\n\n\n\n\ntotal_portfolio &lt;- portfolio_tracking_all %&gt;%\n  group_by(date) %&gt;%\n  summarise(total_value = sum(holding_value), .groups = \"drop\")\n\nggplot(total_portfolio, aes(x = date, y = total_value)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +\n  labs(title = \"Total Portfolio Value Over Time\", y = \"Value (USD)\", x = \"Date\") +\n  scale_y_continuous(labels = scales::dollar)\n\n\n\n\n\n\n\n\n\n\n\n\nSimulated multi-stock portfolio\nLive Yahoo Finance data via tq_get()\nReturn tracking since individual buy dates\nPortfolio-level return and value plots\n\n\ncolnames(portfolio_tracking_all)\n\n [1] \"symbol\"            \"date\"              \"open\"             \n [4] \"high\"              \"low\"               \"close\"            \n [7] \"volume\"            \"adjusted\"          \"return_since_buy\" \n[10] \"current_value\"     \"stock\"             \"buy_date\"         \n[13] \"quantity\"          \"buy_price\"         \"invested_amount\"  \n[16] \"holding_value\"     \"unrealized_return\" \"position_id\"      \n\n\n\n\n\nggplot(stock_data, aes(x = date, y = adjusted, color = symbol)) +\n  geom_line() +\n  labs(title = \"Adjusted Closing Price Over Time\", y = \"Adjusted Price\", x = \"Date\")\n\n\n\n\n\n\n\n\n\n\n\n\nstock_data &lt;- stock_data %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    daily_return = adjusted / lag(adjusted) - 1,\n    rolling_vol_20 = rollapply(daily_return, width = 20, FUN = sd, fill = NA, align = \"right\")\n  ) %&gt;%\n  ungroup()\n\nggplot(stock_data %&gt;% filter(!is.na(rolling_vol_20)), \n       aes(x = date, y = rolling_vol_20, color = symbol)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"20-Day Rolling Volatility (Standard Deviation of Daily Returns)\",\n    x = \"Date\",\n    y = \"Rolling Volatility (Std Dev)\"\n  ) +\n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\nObservations:\n\nTSLA (Purple Line) shows the highest volatility overall. It fluctuates often and peaks above 6%, meaning high price swings daily.\nMSFT (Green Line) is the least volatile, maintaining a very consistent low volatility around 1–2%, reflecting its status as a stable, mature stock.\nNVDA (Cyan) and AMZN (Red) fluctuate in between — but note that NVDA has occasional sharp volatility spikes, likely due to earnings or news events.\nSpikes in volatility (upward jumps) are usually tied to market news, economic events, earnings releases, or crashes/rallies.\nPeriods of low volatility indicate price stability or consolidation phases.\n\n\n\n\n\n\n\n\nportfolio_tracking_all %&gt;%\n  group_by(position_id) %&gt;%\n  summarise(\n    stock = first(stock),\n    buy_date = first(buy_date),\n    mean_return = mean(return_since_buy, na.rm = TRUE),\n    sd_return = sd(return_since_buy, na.rm = TRUE),\n    median_return = median(return_since_buy, na.rm = TRUE),\n    min_return = min(return_since_buy, na.rm = TRUE),\n    max_return = max(return_since_buy, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# A tibble: 5 × 8\n  position_id    stock buy_date   mean_return sd_return median_return min_return\n  &lt;chr&gt;          &lt;chr&gt; &lt;date&gt;           &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1 AMZN_2022-05-… AMZN  2022-05-12       0.393     0.384         0.313    -0.235 \n2 MSFT_2022-02-… MSFT  2022-02-18       0.175     0.254         0.147    -0.269 \n3 NVDA_2022-04-… NVDA  2022-04-05       1.40      1.75          0.750    -0.569 \n4 NVDA_2024-01-… NVDA  2024-01-17       1.06      0.437         1.16      0.0188\n5 TSLA_2022-03-… TSLA  2022-03-10      -0.141     0.237        -0.164    -0.613 \n# ℹ 1 more variable: max_return &lt;dbl&gt;\n\n\nmean_return: Daily gain on average\nsd_return: Daily volatility\nmedian_return: Median\nmin_return: Minimum return\nmax_return: Maximum return\n\n\n\n\nportfolio_tracking_all &lt;- portfolio_tracking_all %&gt;%\n  arrange(stock, buy_date, date) %&gt;%\n  group_by(position_id) %&gt;%\n  mutate(\n    cumulative_return = cumprod(1 + coalesce(return_since_buy, 0))\n  ) %&gt;%\n  ungroup()\n\nggplot(portfolio_tracking_all, aes(x = date, y = return_since_buy, color = position_id)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Cumulative Return Since Buy Date (Per Buy-in)\",\n    x = \"Date\",\n    y = \"Cumulative Return\"\n  ) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ensure daily return is available (if not already calculated)\nstock_data &lt;- stock_data %&gt;%\n  group_by(symbol) %&gt;%\n  arrange(date) %&gt;%\n  mutate(daily_return = adjusted / lag(adjusted) - 1) %&gt;%\n  ungroup()\n\n# Summarise to ensure one return per symbol-date (safety step)\nreturns_clean &lt;- stock_data %&gt;%\n  group_by(date, symbol) %&gt;%\n  summarise(daily_return = mean(daily_return, na.rm = TRUE), .groups = \"drop\")\n\n# Pivot wider\nreturns_matrix &lt;- returns_clean %&gt;%\n  pivot_wider(names_from = symbol, values_from = daily_return)\n\n# Ensure numeric\nreturns_matrix &lt;- returns_matrix %&gt;%\n  mutate(across(-date, as.numeric))\n\n# Compute correlation matrix\nreturns_corr &lt;- cor(returns_matrix %&gt;% select(-date), use = \"pairwise.complete.obs\")\n\n# Plot\ncorrplot(\n  returns_corr,\n  method = \"color\",\n  addCoef.col = \"black\",\n  number.cex = 0.8,\n  title = \"Daily Return Correlation Matrix\",\n  mar = c(0, 0, 2, 0)\n)\n\n\n\n\n\n\n\n\nObservation:\n\nAMZN and MSFT show the highest correlation in your portfolio — likely due to their similar sector dynamics (large-cap tech, index-driven movements).\n\n\n\n\n# Step 1: Calculate mean return and volatility per stock\nreturn_volatility_stats &lt;- stock_data %&gt;%\n  group_by(symbol) %&gt;%\n  summarise(\n    mean_return = mean(daily_return, na.rm = TRUE),\n    volatility = sd(daily_return, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Step 2: Plot the Risk–Return scatter plot\nggplot(return_volatility_stats, aes(x = volatility, y = mean_return, label = symbol)) +\n  geom_point(size = 4, color = \"darkblue\") +\n  geom_text(nudge_y = 0.0005, fontface = \"bold\") +\n  labs(\n    title = \"Return vs Volatility (Risk–Return Tradeoff)\",\n    x = \"Volatility (Standard Deviation of Daily Return)\",\n    y = \"Mean Daily Return\"\n  ) +\n  scale_x_continuous(labels = scales::percent) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Step 1: Filter past 5 years only\nvolume_5yr &lt;- stock_data %&gt;%\n  filter(date &gt;= Sys.Date() %m-% years(5)) %&gt;%\n  mutate(\n    year = year(date),\n    month = month(date, label = TRUE)\n  ) %&gt;%\n  group_by(symbol, year, month) %&gt;%\n  summarise(total_volume = sum(volume, na.rm = TRUE), .groups = \"drop\")\n\n# Step 2: Plot barchart faceted by stock, grouped by year\nggplot(volume_5yr, aes(x = month, y = total_volume, fill = factor(year))) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ symbol, scales = \"free_y\") +\n  labs(\n    title = \"📊 Monthly Trading Volume by Stock (Past 5 Years)\",\n    x = \"Month\", y = \"Total Volume\",\n    fill = \"Year\"\n  ) +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal()"
  },
  {
    "objectID": "Prototype/forecasting.html#correlation-of-time-series-features",
    "href": "Prototype/forecasting.html#correlation-of-time-series-features",
    "title": "Time Series Forecasting",
    "section": "4.5 Correlation of Time Series Features",
    "text": "4.5 Correlation of Time Series Features\nThis step is to help us identify which date components (e.g month, week, quarter) are most correlated with stock prices, which will be useful when building our forecasting model.\n\nlibrary(ggcorrplot)\n\nsig_tbl &lt;- stock_tbl %&gt;%\n  tk_augment_timeseries_signature() %&gt;%\n  select(-Date)\n\nnumeric_tbl &lt;- sig_tbl %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(where(~ sd(.x, na.rm = TRUE) &gt; 0))\n\nnumeric_tbl$Value &lt;- stock_tbl$Value\n\ncorr_with_value &lt;- cor(numeric_tbl, use = \"complete.obs\")[, \"Value\", drop = FALSE]\n\ncorr_df &lt;- as.data.frame(corr_with_value) %&gt;%\n  rownames_to_column(\"feature\") %&gt;%\n  filter(feature != \"Value\")\n\nggplot(corr_df, aes(x = reorder(feature, Value), y = Value)) +\n  geom_col(fill = \"#1f77b4\") +\n  coord_flip() +\n  labs(\n    title = \"Correlation of Time Features with Stock Price (Value)\",\n    x = \"Feature\",\n    y = \"Correlation with Value\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Prototype/forecasting.html#variable-importance",
    "href": "Prototype/forecasting.html#variable-importance",
    "title": "Time Series Forecasting",
    "section": "Variable Importance",
    "text": "Variable Importance\n\nlibrary(vip)\n\nworkflow_fit_xgboost %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 15) +\n  ggtitle(\"XGBoost Feature Importance\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\nAccording to our XGBoost model, the year and seasonality of the year (day-of-year) have the strongest influence on stock price, while specific month dummies have little predictive value."
  }
]